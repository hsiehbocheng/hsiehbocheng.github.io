<!DOCTYPE html><html lang="zh-tw" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>什麼是 RAG｜就像讓裸考的你 open book 考試 | Benson's data.science.ipynb</title><meta name="author" content="Benson｜丞式語言"><meta name="copyright" content="Benson｜丞式語言"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="什麼是 RAG｜就像讓裸考的你 open book 考試這次希望和大家介紹：  RAG 是什麼，為什麼要使用 RAG 簡單使用 Hugging Face 實作具有檢索功能的聊天機器人  RAG（Retrieval-Augmented Generation）由 Patrick Lewis 等人於 2020 年提出，是一種 AI 框架，旨在通過提供外部資料知識來提升 LLM（大型語言模型）的回答質量和">
<meta property="og:type" content="article">
<meta property="og:title" content="什麼是 RAG｜就像讓裸考的你 open book 考試">
<meta property="og:url" content="http://hsiehbocheng.github.io/2024/06/02/rag-intro/index.html">
<meta property="og:site_name" content="Benson&#39;s data.science.ipynb">
<meta property="og:description" content="什麼是 RAG｜就像讓裸考的你 open book 考試這次希望和大家介紹：  RAG 是什麼，為什麼要使用 RAG 簡單使用 Hugging Face 實作具有檢索功能的聊天機器人  RAG（Retrieval-Augmented Generation）由 Patrick Lewis 等人於 2020 年提出，是一種 AI 框架，旨在通過提供外部資料知識來提升 LLM（大型語言模型）的回答質量和">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="http://hsiehbocheng.github.io/2024/06/02/rag-intro/rag-intro-cover.png">
<meta property="article:published_time" content="2024-06-01T16:28:18.000Z">
<meta property="article:modified_time" content="2024-06-03T16:27:45.528Z">
<meta property="article:author" content="Benson｜丞式語言">
<meta property="article:tag" content="nlp">
<meta property="article:tag" content="rag">
<meta property="article:tag" content="llm">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://hsiehbocheng.github.io/2024/06/02/rag-intro/rag-intro-cover.png"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://hsiehbocheng.github.io/2024/06/02/rag-intro/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '什麼是 RAG｜就像讓裸考的你 open book 考試',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-04 00:27:45'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.1"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/memoji.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About Me</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2024/06/02/rag-intro/rag-intro-cover.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Benson's data.science.ipynb"><span class="site-name">Benson's data.science.ipynb</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About Me</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">什麼是 RAG｜就像讓裸考的你 open book 考試</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-06-01T16:28:18.000Z" title="Created 2024-06-02 00:28:18">2024-06-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-06-03T16:27:45.528Z" title="Updated 2024-06-04 00:27:45">2024-06-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/rag/">rag</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="什麼是 RAG｜就像讓裸考的你 open book 考試"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="什麼是-RAG｜就像讓裸考的你-open-book-考試"><a href="#什麼是-RAG｜就像讓裸考的你-open-book-考試" class="headerlink" title="什麼是 RAG｜就像讓裸考的你 open book 考試"></a><strong>什麼是 RAG｜就像讓裸考的你 open book 考試</strong></h1><p>這次希望和大家介紹：</p>
<ol>
<li>RAG 是什麼，為什麼要使用 RAG</li>
<li>簡單使用 Hugging Face 實作具有檢索功能的聊天機器人</li>
</ol>
<p><strong>RAG（Retrieval-Augmented Generation）</strong>由 Patrick Lewis 等人於 2020 年提出，是一種 AI 框架，旨在通過提供外部資料知識來提升 LLM（大型語言模型）的回答質量和準確性。這有點像在沒有學習過相關知識的情況下進行考試的考生，在考試中使用開卷答題的方式來彌補知識的不足。具體來說，當 LLM 對某些特定資料的回覆不足時，RAG 可以提供外部資料來輔助回答問題。</p>
<p>舉一個簡單的例子來說明，假設我們問 LLM「為什麼 ML 需要正規化？」如果這個模型沒有學過機器學習的相關知識，它可能不知道正規化是什麼意思，以及正規化對機器學習建模的影響。但如果我們能夠提供一份關於機器學習的書籍，LLM 就能夠在回答「為什麼 ML 需要正規化？」這個問題時，檢索書籍中語意最相近的段落，並基於這些段落來回答問題。這個過程就是 RAG 的工作流程：提供額外資訊給 LLM，讓它進行檢索並基於檢索到的資訊來回答問題。<br><img src="rag-as-openbook.png" width="100%" title="RAG 就像是裸考時 open book"></p>
<h2 id="為什麼要使用-RAG？"><a href="#為什麼要使用-RAG？" class="headerlink" title="為什麼要使用 RAG？"></a>為什麼要使用 RAG？</h2><p>如同一開始所提到的，LLM 因為訓練資料的限制，先天上有一些問題導致在實際應用時需要進行微調，否則 LLM 的回答可能不會達到我們的預期。</p>
<h3 id="LLM-不擅長的事"><a href="#LLM-不擅長的事" class="headerlink" title="LLM 不擅長的事"></a>LLM 不擅長的事</h3><ol>
<li><p>缺乏最新、私人的資料<br>LLM 只根據訓練資料進行回答，它對於語言的理解以及基本常識有很強的能力，但如果使用者的問題過於特定，超出訓練集的資料內容，LLM 無法提供準確、有用的答案。例如，詢問 LLM「現在的總統是誰」或「我們公司的軟體操作問題」。</p>
</li>
<li><p>對於專業問題回答的幻覺<br>由於資料集的分佈問題，某些特定領域的資料一定佔少數，而通用型 LLM 並非在專業領域知識的背景下訓練，回答時常會充滿幻覺，並非真正有用的答案。例如，當涉及法律、醫療等專業知識時，LLM 的回答通常會失準。</p>
</li>
</ol>
<h2 id="什麼是-RAG？"><a href="#什麼是-RAG？" class="headerlink" title="什麼是 RAG？"></a>什麼是 RAG？</h2><p>針對以上問題，提出了一種將 LLM 與額外知識庫整合的架構，即為 RAG。透過給 LLM 額外的知識、資料，讓 LLM 可以給出可靠、準確的回應。以下介紹 RAG 的工作方式及其各環節涉及到的問題和可能的解決技術。</p>
<p>簡單來說 RAG 得步驟有兩點：</p>
<h3 id="檢索（Retrieval）"><a href="#檢索（Retrieval）" class="headerlink" title="檢索（Retrieval）"></a>檢索（Retrieval）</h3><blockquote>
<p>依據 User 的問題從額外提供的資料中找出最相關、可以回答該問題的文件、段落。</p>
</blockquote>
<p>在檢索階段，我們需要</p>
<ol>
<li><p><strong>收集資料</strong><br>我們需要收集該應用所需要的可能資料，例如：內外規比對機器人需要內部與外部的法規文件、商品客服機器人需要各商品的資料。</p>
</li>
<li><p><strong>資料切分</strong><br>以內外法規比對為例，內部法規可能是一份超過千頁的 pdf 檔案，我們需要將其依據章節、字數分成不同的部分，這樣每個資料都代表特定的主題，避免我們在檢索時，提供太多不需要的資訊，而增加 LLM 回答的不可控性。而將資料切分的過程我們稱為 Chunking，每一份資料則為一份 Chunk。<br>以下為一些進行 Chunk 時可以使用的技術，以提升 Chunk 品質：</p>
<ol>
<li>Sliding window<br> 在切分時，每一份 Chunk 會保留前後 Chunk 的資訊。</li>
<li>Metadata filtering<br>Metadata 包含了許多關於資料的重要資訊，可以在一開始藉由 Metadata 過濾掉不相關的資料，例如：時間、類別等。</li>
<li>Abstract Embedding<br>將每一份 Chunk 先進行摘要，可有效的壓縮並保留資訊，以提升後續做 Embedding 時的表現。</li>
<li>Graph Indexing<br>加入每一份 Chunk 的關係。</li>
<li>Semantic Chunkking：基於語意而非字數做文本的切割。</li>
</ol>
</li>
<li><p><strong>語意搜尋</strong><br>準備好 Chunk 後，我們需要一個嵌入模型 Embedding Model 幫我們將 Chunk 以向量的方式表達其語意特徵，我們可以透過將其與 User 的向量進行相似度運算，比較出哪一部分的 Chunk 與 User 的問題最相似。<br>而如何真正理解 User 的問題，進而找到相關的段落，我們可以做一些 Query Translation：</p>
<ol>
<li>Query Rewriting<br>指示 LLMs 針對檢索任務重新撰寫 Query。</li>
<li>Multi-query<br>有時後 User 的問題可能包含多個含義、問題，透過 LLM 將 User 的問題拆成多個子問題再進行檢索。</li>
<li>RAG-Fusion<br>當 User 對於問題不夠明確時，透過 LLM 將問題換句話說，轉換成多個意思相近的 Query 後進行檢索，將檢索結果進行綜合排序得到較好的檢索結果。</li>
<li>Step-back<br>利用 LLM 猜想 User 問題的抽象概念，也就退後一步思考 User 可能的意圖。</li>
<li>HyDE<br>藉由 LLM 生成「假想的回答」，再依據假想的回答進行答案的檢索，通過比對「假想」和「真實」資料中的差異，捕捉語意。</li>
</ol>
</li>
</ol>
<h3 id="增強生成（Augmented-Generation）"><a href="#增強生成（Augmented-Generation）" class="headerlink" title="增強生成（Augmented-Generation）"></a>增強生成（Augmented-Generation）</h3><blockquote>
<p>將檢索到的資料與 User 的問題結合，透過生成器產生順暢、可理解、準確地回答，通常將資料一起餵給訓練好的 LLM，讓其統整上下文訊息回答。</p>
</blockquote>
<p>依賴訓練好的 LLM 回答通常可以達到不錯的效果，但依舊會遇到一些問題，例如 1. 上下文長度限制 2. 受冗餘資訊影響生成 3. 檢索的結果並不包含有用的資訊，所以有一些研究在於專注擷取資訊的的後處理，處理第一階段檢索的資料，將其過濾、壓縮、最佳化提升檢索的資料品質，藉以提升模型回答，主要有兩種做法：</p>
<ol>
<li>Re-Ranking<br>   LLM 會受到上下文長度限制，故藉由 Re-Ranking 將真正重要、相關的文件排序在前面，限制文件數量，解決上下文長度限制以及檢索資料的品質。</li>
<li>Self-RAG<br>   透過 LLM 反思、修正檢索的結果，其中涉及到 1. 評估是否要進行檢索 2. 評估檢索語回答的相關性與準確性，挑選最佳組進行回答。</li>
</ol>
<h2 id="簡單的-RAG-實作"><a href="#簡單的-RAG-實作" class="headerlink" title="簡單的 RAG 實作"></a>簡單的 RAG 實作</h2><p>到了 Demo 時間！我們將簡單實作一個具有檢索功能的聊天機器人，使用 Hugging Face 的 Pipeline 與 Conversation 能非常迅速的實作。在這之前，還是跟大家介紹一下實作 RAG 你會需要的工具。<br><img src="rag-tools.png" width="100%"></p>
<ol>
<li><p><strong>Models</strong><br>簡單來說我們需要兩種模型：1. Embedding Model 2. ChatModel。<br>我們需要 Embedding Model 協助我們進行語意搜尋，ChatModel 將檢索結果與 User 問題結合，進行回覆。</p>
<ul>
<li><strong>Embedding Model</strong>： 我們可以從 Hugging face 中的 feature-extraction Model 尋找，或是直接使用 Sentence-Transformers 套件。</li>
<li><strong>ChatModel</strong>：我們可以從開源的模型庫，例如 Hugging face hub or Ollama 下載，或是使用閉源模型的 API。<img src="llm-choice.png" width="100%"></li>
</ul>
</li>
<li><p><strong>Frameworks</strong><br>如果 Pandas 之於數據分析、Scikit-learn 之於機器學習，我們也需要一些框架來協助我們實作 RAG，以更快速完成上面所介紹的技術（當然你也可以自行手刻），目前主流框架有 1. Langchain 2. Llamaindex。</p>
</li>
</ol>
<p>在這次的 demo 中，我們將簡單的使用 Hugging face 的 Pipeline 與 Conversation 來實作 RAG。</p>
<h2 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h2><p><a target="_blank" rel="noopener" href="https://github.com/hsiehbocheng/llama_club/blob/main/R1/R1-HW.ipynb">code</a></p>
<ol>
<li><strong>準備 ChatModel</strong><br>我們使用 Hugging Face 下載模型，範例中我們使用聯發科的 <code>MediaTek-Research/Breeze-7B-32k-Instruct-v1_0</code>，利用 AutoModelForCasualLM 實例化模型，再傳入帶有 <code>text-generation</code> 任務的 pipeline 中，完成 chatmodel 的初始化。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">model_id = <span class="string">&#x27;MediaTek-Research/Breeze-7B-32k-Instruct-v1_0&#x27;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(</span><br><span class="line">    model_id)</span><br><span class="line">hf_model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    model_id,</span><br><span class="line">    trust_remote_code=<span class="literal">True</span>,</span><br><span class="line">    device_map=<span class="string">&#x27;auto&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chatbot = pipeline(</span><br><span class="line">    <span class="string">&quot;text-generation&quot;</span>, </span><br><span class="line">    model=hf_model, </span><br><span class="line">    tokenizer=tokenizer, <span class="comment"># Tokenizer，要與模型匹配，主要提供 chat 模式時的特殊符號</span></span><br><span class="line">    max_new_tokens=<span class="number">1024</span>, <span class="comment"># 模型最多可以生成多少字</span></span><br><span class="line">    return_full_text=<span class="literal">False</span> <span class="comment"># 控制 pipeline 只輸出 AI Message</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><strong>聊天記錄前處理</strong><br>聊天式模型，例如 ChatGPT，基本上是透過 text-generation 作為基礎模型，進一步訓練模型以實現聊天功能。因此，在 Hugging Face 上找到的任何支持 text-generation 任務的模型都可以用來實現聊天功能。</li>
</ol>
<p>在進行聊天任務時，模型需要一些特殊符號來區分每一段訊息是來自於使用者（User）、AI 還是系統提示（System Prompt）。各個模型的特殊符號可能不盡相同，需要參考官方文件來了解。例如，在聯發科的 Breeze 模型中，使用 [INST] 和 [&#x2F;INST] 作為區隔符號。</p>
<p>使用模型時，我們需要在文字中加入這些特殊符號，才能充分發揮模型的聊天能力。通常，我們會使用 list of dict 的方式儲存聊天記錄，使用 role 區別 user 和 ai，content 代表內容，而 Hugging Face 的模型也支援這樣的格式。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">chat_history = [</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Hello, who are you?&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;I am an AI developed by OpenAI. How can I assist you today?&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我們可以透過實例化 Conversation 這個 class，透過 add_user_input 與 append_response 新增歷史使用者輸入與模型回覆，將資料變為上述的資料格式再送給模型進行推理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Conversation</span><br><span class="line">conversation = Conversation() <span class="comment"># 建立一個對話 Conversation 物件</span></span><br></pre></td></tr></table></figure>
<p>利用 <code>add_user_input</code> 新增 user 聊天記錄：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conversation.add_user_input(<span class="string">&quot;provided information: the name of repo is bert-base-uncased. Based on the provided information, what is the name of repo?&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;目前聊天記錄：<span class="subst">&#123;conversation.messages&#125;</span>&quot;</span>) <span class="comment"># conversation.messages 可以直接丟給 chatbot 得到回覆</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>目前聊天記錄：[{‘role’: ‘user’, ‘content’: ‘provided information: the name of repo is bert-base-uncased. Based on the provided information, what is the name of repo?’}]</p>
</blockquote>
<p>將 <code>conversation.messages</code> 丟給 chatbot 得到回覆：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chatbot_result = chatbot(conversation.messages)</span><br><span class="line"><span class="built_in">print</span>(chatbot_result)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>[{‘generated_text’: ‘根據提供的信息，repo的名称是”bert-base-uncased”。’}]</p>
</blockquote>
<p>將 chatbot 的回覆以 <code>append_respons</code> 的方法加入 conversation 中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conversation.append_response(chatbot_result[<span class="number">0</span>][<span class="string">&#x27;generated_text&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;目前聊天記錄：<span class="subst">&#123;conversation.messages&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>目前聊天記錄：[{‘role’: ‘user’, ‘content’: ‘provided information: the name of repo is bert-base-uncased. Based on the provided information, what is the name of repo?’}, {‘role’: ‘assistant’, ‘content’: ‘根據提供的信息，repo的名称是”bert-base-uncased”。’}]</p>
</blockquote>
<ol start="3">
<li><strong>Embedding Model</strong><br>我們透過 Embedding Model 將文件與 User query 轉成語意向量，使用相似度進行匹配，我們可以在 Hugging Face 中於 Task 以 feature-extraction 找到 Embedding model，也可以直接使用 sentence-transformers 套件將句子轉成向量。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line">embedding_model = SentenceTransformer(<span class="string">&quot;intfloat/multilingual-e5-large&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用 encode 得到 sentence 的 embedding</span></span><br><span class="line">embedding_model.encode(<span class="string">&quot;哈囉，這是一個句子&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>array([ 0.03142083, -0.01894771, -0.00766944, …, -0.02039895,<br>       -0.01210877,  0.03742645], dtype&#x3D;float32)</p>
</blockquote>
<p>有了向量之後，我們就可以利用迴圈與 cosine simialrity 進行匹配，找出最相似的句子，下面舉一個簡單的例子，我們計算 query 與 source_sentence 中所有句子 embedding 的 cosine similarity，並選出最相似的句子，得到與「為什麼 ML 需要做正規化」最相似文本是 「Regularization is important!」。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_cosine_similarity</span>(<span class="params">vec1, vec2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;為什麼 ML 需要做正規化&quot;</span></span><br><span class="line"></span><br><span class="line">source_sentence = [</span><br><span class="line">    <span class="string">&#x27;Regularization is important!&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Dropout is important!&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Missing Data Handling is important!&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">most_related_sentence = <span class="literal">None</span></span><br><span class="line">max_similarity = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sentence <span class="keyword">in</span> source_sentence:</span><br><span class="line">    sim = calculate_cosine_similarity(</span><br><span class="line">    embedding_model.encode(query),</span><br><span class="line">    embedding_model.encode(sentence)</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> sim &gt; max_similarity:</span><br><span class="line">        most_related_sentence = sentence</span><br><span class="line">        max_similarity = sim</span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;query&#125;</span> vs <span class="subst">&#123;sentence&#125;</span> similarity: <span class="subst">&#123;sim&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;與「<span class="subst">&#123;query&#125;</span>」最相似文本：<span class="subst">&#123;most_related_sentence&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>為什麼 ML 需要做正規化 vs Regularization is important! similarity: 0.86 </p>為什麼 ML 需要做正規化 vs Dropout is important! similarity: 0.80 </p> 為什麼 ML 需要做正規化 vs Missing Data Handling is important! similarity: 0.81 </p> &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</p> 與「為什麼 ML 需要做正規化」最相似文本：Regularization is important!</p>
</blockquote>
<ol start="4">
<li><strong>整合在一起！</strong><br>我們準備一個 list 當中包含了想要檢索的資料，在 while 迴圈中：</li>
<li>User 輸入 query</li>
<li>透過 Embedding Model 計算 query 與 source_sentence 中所有句子的 cosine similarity，選出最相近的句子</li>
<li>將 query 與最相近的句子一起傳入 conversation.messages 並送入 chatbot 得到回覆</li>
<li>將 chatbot 回覆加入 conversation.messages</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">qa_data = [</span><br><span class="line">    ...,</span><br><span class="line"></span><br><span class="line">    ...,</span><br><span class="line"></span><br><span class="line">    ...,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_answer</span>(<span class="params">query: <span class="built_in">str</span>, source: <span class="type">List</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">    most_related_sentence = <span class="literal">None</span></span><br><span class="line">    max_similarity = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> source:</span><br><span class="line">        sim = calculate_cosine_similarity(</span><br><span class="line">        embedding_model.encode(query),</span><br><span class="line">        embedding_model.encode(sentence)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> sim &gt; max_similarity:</span><br><span class="line">            most_related_sentence = sentence</span><br><span class="line">            max_similarity = sim</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> most_related_sentence</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_cosine_similarity</span>(<span class="params">vec1, vec2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">user_query = <span class="built_in">input</span>(<span class="string">&quot;&gt;&gt;&gt;&quot;</span>)</span><br><span class="line">conversation = Conversation()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> user_query.lower() != <span class="string">&quot;bye&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;user: <span class="subst">&#123;user_query&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 尋找最相似的文件</span></span><br><span class="line">    answer = get_answer(user_query, qa_data)</span><br><span class="line">    llm_input = <span class="string">f&quot;&quot;&quot;請你基於以下資訊回答使用者的問題</span></span><br><span class="line"><span class="string">    <span class="subst">&#123;answer&#125;</span></span></span><br><span class="line"><span class="string">    ===</span></span><br><span class="line"><span class="string">    問題：<span class="subst">&#123;user_query&#125;</span></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    conversation.add_user_input(llm_input)</span><br><span class="line">    <span class="comment"># 將 conversation.messages 丟給 chatbot</span></span><br><span class="line">    chatbot_result = chatbot(conversation.messages)[<span class="number">0</span>][<span class="string">&#x27;generated_text&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;AI: <span class="subst">&#123;chatbot_result&#125;</span>&quot;</span>)</span><br><span class="line">    conversation.append_response(chatbot_result)</span><br><span class="line">    </span><br><span class="line">    user_query = <span class="built_in">input</span>(<span class="string">&quot;&gt;&gt;&gt;&quot;</span>)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<p>如此一來，就完成一個簡單的具有檢索功能 chatbot 了！🎉</p>
<h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2005.11401">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a><br><a target="_blank" rel="noopener" href="https://medium.com/@cch.chichieh/rag-retrieval-augmented-generation-%E7%82%BA%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86%E6%8F%AD%E9%96%8B%E6%96%B0%E7%AF%87%E7%AB%A0-fced76fdb8b9">RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://hsiehbocheng.github.io">Benson｜丞式語言</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://hsiehbocheng.github.io/2024/06/02/rag-intro/">http://hsiehbocheng.github.io/2024/06/02/rag-intro/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/nlp/">nlp</a><a class="post-meta__tags" href="/tags/rag/">rag</a><a class="post-meta__tags" href="/tags/llm/">llm</a></div><div class="post_share"><div class="social-share" data-image="/2024/06/02/rag-intro/rag-intro-cover.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/04/20/word-seg/" title="淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測"><img class="cover" src="/2024/04/20/word-seg/ws_gamma.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next</div><div class="next_info">淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2024/04/17/bert-cls/" title="Building Tweet Classification Models with BERT 🤗"><img class="cover" src="/2024/04/17/bert-cls/dalle.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-17</div><div class="title">Building Tweet Classification Models with BERT 🤗</div></div></a></div><div><a href="/2024/03/14/hello%20regexp/" title="Getting Started with Regexp, Simple and Clear 🤗"><img class="cover" src="/2024/03/14/hello%20regexp/regexo.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-14</div><div class="title">Getting Started with Regexp, Simple and Clear 🤗</div></div></a></div><div><a href="/2024/04/20/word-seg/" title="淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測"><img class="cover" src="/2024/04/20/word-seg/ws_gamma.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-20</div><div class="title">淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/memoji.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Benson｜丞式語言</div><div class="author-info__description">第一年菜鳥資料科學家, 
腦容量不好, 所以把日常工作所學的筆記整理上來, 希望幫助得到未來的自己與大家，請大家多多指教～ 
</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/hsiehbocheng" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://medium.com/@bensonhsieh" target="_blank" title="Medium"><i class="fa-brands fa-medium"></i></a><a class="social-icon" href="https://www.instagram.com/data.science.ipynb?igsh=MWF6bTZkdW16ZWp4ZA%3D%3D&amp;utm_source=qr" target="_blank" title="Instagram"><i class="fa-brands fa-instagram"></i></a><a class="social-icon" href="https://www.linkedin.com/in/%E5%8D%9A%E4%B8%9E-%E8%AC%9D-4396b7235/" target="_blank" title="LinkedIn"><i class="fa-brands fa-linkedin-in"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%80%E9%BA%BC%E6%98%AF-RAG%EF%BD%9C%E5%B0%B1%E5%83%8F%E8%AE%93%E8%A3%B8%E8%80%83%E7%9A%84%E4%BD%A0-open-book-%E8%80%83%E8%A9%A6"><span class="toc-number">1.</span> <span class="toc-text">什麼是 RAG｜就像讓裸考的你 open book 考試</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%82%BA%E4%BB%80%E9%BA%BC%E8%A6%81%E4%BD%BF%E7%94%A8-RAG%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">為什麼要使用 RAG？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LLM-%E4%B8%8D%E6%93%85%E9%95%B7%E7%9A%84%E4%BA%8B"><span class="toc-number">1.1.1.</span> <span class="toc-text">LLM 不擅長的事</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E9%BA%BC%E6%98%AF-RAG%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">什麼是 RAG？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AA%A2%E7%B4%A2%EF%BC%88Retrieval%EF%BC%89"><span class="toc-number">1.2.1.</span> <span class="toc-text">檢索（Retrieval）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E5%BC%B7%E7%94%9F%E6%88%90%EF%BC%88Augmented-Generation%EF%BC%89"><span class="toc-number">1.2.2.</span> <span class="toc-text">增強生成（Augmented-Generation）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B0%A1%E5%96%AE%E7%9A%84-RAG-%E5%AF%A6%E4%BD%9C"><span class="toc-number">1.3.</span> <span class="toc-text">簡單的 RAG 實作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#demo"><span class="toc-number">1.4.</span> <span class="toc-text">demo</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%83%E8%80%83%E8%B3%87%E6%96%99"><span class="toc-number">1.5.</span> <span class="toc-text">參考資料</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/06/02/rag-intro/" title="什麼是 RAG｜就像讓裸考的你 open book 考試"><img src="/2024/06/02/rag-intro/rag-intro-cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="什麼是 RAG｜就像讓裸考的你 open book 考試"/></a><div class="content"><a class="title" href="/2024/06/02/rag-intro/" title="什麼是 RAG｜就像讓裸考的你 open book 考試">什麼是 RAG｜就像讓裸考的你 open book 考試</a><time datetime="2024-06-01T16:28:18.000Z" title="Created 2024-06-02 00:28:18">2024-06-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/20/word-seg/" title="淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測"><img src="/2024/04/20/word-seg/ws_gamma.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測"/></a><div class="content"><a class="title" href="/2024/04/20/word-seg/" title="淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測">淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測</a><time datetime="2024-04-20T09:55:58.000Z" title="Created 2024-04-20 17:55:58">2024-04-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/17/bert-cls/" title="Building Tweet Classification Models with BERT 🤗"><img src="/2024/04/17/bert-cls/dalle.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Building Tweet Classification Models with BERT 🤗"/></a><div class="content"><a class="title" href="/2024/04/17/bert-cls/" title="Building Tweet Classification Models with BERT 🤗">Building Tweet Classification Models with BERT 🤗</a><time datetime="2024-04-16T18:02:22.000Z" title="Created 2024-04-17 02:02:22">2024-04-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/16/multithreading/" title="Dive into Multithreading in Python!"><img src="/2024/04/16/multithreading/multi_cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Dive into Multithreading in Python!"/></a><div class="content"><a class="title" href="/2024/04/16/multithreading/" title="Dive into Multithreading in Python!">Dive into Multithreading in Python!</a><time datetime="2024-04-15T18:01:10.000Z" title="Created 2024-04-16 02:01:10">2024-04-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/07/pyspark-install-on-mac/" title="PySpark MacOS Installation: Step-by-Step Guide 🐍"><img src="/2024/04/07/pyspark-install-on-mac/pyspark_install_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PySpark MacOS Installation: Step-by-Step Guide 🐍"/></a><div class="content"><a class="title" href="/2024/04/07/pyspark-install-on-mac/" title="PySpark MacOS Installation: Step-by-Step Guide 🐍">PySpark MacOS Installation: Step-by-Step Guide 🐍</a><time datetime="2024-04-07T02:11:34.000Z" title="Created 2024-04-07 10:11:34">2024-04-07</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/2024/06/02/rag-intro/rag-intro-cover.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Benson｜丞式語言</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="Chat"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(()=>{
  const getGiscusTheme = theme => {
    return theme === 'dark' ? 'dark' : 'light'
  }

  const loadGiscus = () => {
    const config = Object.assign({
      src: 'https://giscus.app/client.js',
      'data-repo': 'hsiehbocheng/hsiehbocheng.github.io',
      'data-repo-id': 'R_kgDOLc8jAQ',
      'data-category-id': 'DIC_kwDOLc8jAc4Cegf-',
      'data-mapping': 'pathname',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true
    },{"data-mapping":"pathname","data-strict":0})

    const ele = document.createElement('script')
    for (let key in config) {
      ele.setAttribute(key, config[key])
    }
    document.getElementById('giscus-wrap').appendChild(ele)
  }

  const changeGiscusTheme = theme => {
    const sendMessage = message => {
      const iframe = document.querySelector('iframe.giscus-frame')
      if (!iframe) return
      iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app')
    }

    sendMessage({
      setConfig: {
        theme: getGiscusTheme(theme)
      }
    });
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if ('Giscus' === 'Giscus' || !true) {
    if (true) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment= loadGiscus
  }
})()</script></div><script id="canvas_nest" defer="defer" color="205,205,205" opacity="0.9" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>