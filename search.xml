<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>淺談中文斷詞｜中文斷詞的辛酸血淚與新詞偵測</title>
      <link href="/2024/04/20/word-seg/"/>
      <url>/2024/04/20/word-seg/</url>
      
        <content type="html"><![CDATA[<p>今天我想分享關於斷詞的一些辛酸血淚。相信那些早期從事NLP相關任務的人都經歷過斷詞不準確帶來的困擾。在傳統的NLP任務中，斷詞的品質直接影響後續分析的效果，特別是在中文文本分析中更是如此。因此，雖然斷詞工作看似枯燥且乏味，它卻是NLP中極為重要的一環，許多研究和工具都在不斷嘗試改善斷詞的效能。</p><p>今天我將分享以下三個要點：</p><p>常見的斷詞技術與工具<br>斷詞時常遇到的問題<br>新詞偵測的方法</p><h2 id="為什麼要做斷詞？如何理解一種語言？"><a href="#為什麼要做斷詞？如何理解一種語言？" class="headerlink" title="為什麼要做斷詞？如何理解一種語言？"></a>為什麼要做斷詞？如何理解一種語言？</h2><p>想象一下我們學習語言的過程：我們先學習個別的字詞，再學習如何將它們組合起來形成具有意義的句子。例如，從「爸爸、媽媽、玩具…」到「爸爸給我買了玩具」。</p><img src="ws_human.png" width="100%"><p>對機器來說也是一樣，我們不會要求機器直接讀懂每句話，而是要將其拆分為更小的單位，例如單字（charactor）、詞（word）再做排列組合。</p><h2 id="常見的斷詞方法與套件"><a href="#常見的斷詞方法與套件" class="headerlink" title="常見的斷詞方法與套件"></a>常見的斷詞方法與套件</h2><p>斷詞可分為兩大方法：1. Ruled Based 2. Learning Based</p><ol><li>Ruled Based<br>這種方法依靠預定義的詞典，通過從句子的前端或後端開始匹配來進行斷詞，常見的方法包括正向最大匹配法、逆向最大匹配法和雙向最大匹配法。</li><li>Learning Based<br> 這類方法利用機器學習或深度學習模型，通過訓練數據讓模型學會如何進行斷詞。例如，隱藏式馬可夫模型（HMM）和基於transformer的模型。這些模型通常使用BIES標記法，來標識一個字在詞中的位置，分別代表該字為一個詞的開始（begging）、中間（intermediate）、結尾（end）或是本單單一組成一詞（singls-character）。<br> 例如：「爸爸買玩具給我」可以斷詞為：「爸爸&#x2F;買&#x2F;玩具&#x2F;給&#x2F;我」，則標記結果為「爸<font color= #A9A9A9>（B）</font>爸<font color= #A9A9A9>（E）</font>買<font color= #A9A9A9>（S）</font>玩<font color= #A9A9A9>（B）</font>具<font color= #A9A9A9>（E）</font>給<font color= #A9A9A9>（S）</font>我<font color= #A9A9A9>（S）</font>」BESBESS。</li></ol><p>而 HMM 或是 Transformer 的模型細節則不在此展開，之後有機會再分享。<br>而常見的 Jieba 則是利用 Ruled based 做第一階段的斷詞，再以 HMM 的方式進一步斷詞語新詞偵測。<br>其他常見的斷詞工具還有</p><ol><li>MONPA</li><li>ckip tagger</li><li>ckip_transformer</li><li>Articut</li></ol><h2 id="斷詞的痛？斷詞怎麼斷不好"><a href="#斷詞的痛？斷詞怎麼斷不好" class="headerlink" title="斷詞的痛？斷詞怎麼斷不好"></a>斷詞的痛？斷詞怎麼斷不好</h2><p>中文的結構使得斷詞尤為困難，因為詞與詞之間沒有明顯的界限，這導致以下問題：</p><ol><li><p>歧義<br>同一句話可能有多種不同的斷詞方式，這包括組合型歧義（不同斷詞方式對意義影響不大）和真歧義（不同斷詞方式意義完全不同）。</p><ol><li>組合型歧義<br>切法不同並沒有導致意義上多大的<blockquote><p>我、在、國泰、產險、數據、科技、發展部、打工 vs<br>我、在、國泰產險、數據科技發展部、打工</p></blockquote></li></ol><p>差別在於當情境是跟全台灣金融業打工仔比較時，上面的斷詞結果或許較有代表性，<br>但當我今天是在分析國泰內部的相關文字資料時，下面的斷詞結果可能會更符合情境。</p><ol start="2"><li>真歧義<br>切法不同，語意會完全不同。<blockquote><p>我、買了、一份、超值、保險、套餐 vs<br>我、買了、一份、超值、保險套、餐</p></blockquote></li></ol></li><li><p>未知詞 OOV<br>現有工具中，訓練用的文本資料通常是新聞、書籍、演講等，導致：</p><ol><li>人名</li><li>年代久遠 ↔ 趨勢新詞</li><li>書面正式用語 ↔ 對話、論壇</li><li>領域遷移 jieba 人民日報 ↔ ckip 中央社CNA</li></ol><p> 直接在特殊領域上應用通常會有很大的 performance drop</p><p> 例如醫療、金融、法律、鄉民等等，而中國與台灣在用語上的差異也會導致繁體中文的斷詞效度較低<br> 以 jieba 斷詞為例，我爬取了一些新聞文章，嘗試斷詞，而 jieba 對於一些論壇用語、專有名詞無法判別其應為一個字詞：</p><blockquote><p>美式、賣場、<font color= red>好式</font>、<font color= red>多</font>、的、販售、品項、豐富<br> 年底、<font color= red>九、合一</font>、大選、逐漸、逼近<br> 你、個、<font color= red>活網、仔</font><br> 我、今天、宵夜、要、吃、<font color= red>涼</font>、<font color= red>麵</font>、配、<font color= red>三合</font>、<font color= red>一味</font>、<font color= red>增湯</font></p></blockquote></li></ol><h2 id="斷詞斷不好怎麼辦！"><a href="#斷詞斷不好怎麼辦！" class="headerlink" title="斷詞斷不好怎麼辦！"></a>斷詞斷不好怎麼辦！</h2><ol><li><p>換個模型吧<br>雖然這聽起來可能像是無用的建議，實際上換一個模型有時候真的可以解決問題，而且性價比很高。我們需要考慮的關鍵問題是：這個模型的訓練資料與我們的分析目標資料之間的分佈是否相似？在不同的領域，即便使用相同的語言，詞彙出現的模式也可能完全不同。因此，找到一個更適合當前數據的模型，或者用自己的數據來訓練模型，是解決斷詞問題的有效策略之一。比如，使用 jieba 斷詞系統未能正確處理的文本，改用 ckip_transformer 模型後，可以看到斷詞質量有了明顯的提升。</p><blockquote><p>美式、賣場、<font color= red>好式多</font>、的、販售、品項、豐富<br>年底、<font color= red>九合一</font>、大選、逐漸、逼近<br>你、個、<font color= red>活網仔</font><br>我、今天、宵夜、要、吃、<font color= red>涼麵</font>、配、<font color= red>三合一</font>、<font color= red>味增湯</font></p></blockquote></li><li><p>新增辭典字詞<br>上網尋找領域字典，或請專家羅列常用字詞，針對特定領域的專業術語進行字典的擴充。這種方法尤其適用於專業領域，例如醫學、法律或科技等，這些領域經常會有大量的專業術語和新詞。透過新增這些專業字詞到斷詞工具的字典中，可以顯著提升斷詞的準確性和相關文本分析的質量。例如，對於金融領域，可以新增如「量化緩和」、「加密貨幣」等新興術語，這樣的做法能幫助模型更好地理解和處理專業文本。</p></li><li><p>新詞指標<br>在一些學術文獻和網絡資源中，我們可以找到多種偵測新詞的方法。這些方法通常利用一些統計指標來判斷一個詞是否應被視為新詞，當這些詞的表現超過特定的閾值時，就可以被認定為新詞。主要的偵測新詞指標包括：</p><ol><li>詞頻<br>這是通過計算一個詞（如n-gram）在文本中出現的次數來進行評估。例如，如果「皮卡丘」的出現次數超過某個預設的閾值，則可能將其認定為新詞。</li><li>凝結度<br>這個指標評估若干個字組成的詞出現在一起的概率是否高於這些字分開出現的概率。例如，如果「皮卡丘」作為一個整體出現的概率大於「皮」和「卡丘」各自出現的概率之乘積，則認為「皮卡丘」具有高凝結度。</li><li>自由度<br>這個指標考量一個詞在文本中的使用自由度，也就是該詞左右鄰近字的變化程度。舉例來說，在句子「小智收服了皮卡丘，但是皮卡丘就是不願意住進寶貝球裡」中，「皮卡丘」周圍的字（如「了」和「是」在左邊，「，」和「就」在右邊）表現出高度的變化，這表明「皮卡丘」在文本中的使用具有高自由度，支持將其視為一個獨立的詞。</li></ol></li></ol><p>我們可以透過上述組合上述指標，設定閥值判斷新詞，流程大致上如下圖：<br><img src="ws_flow.png" width="100%"><br>當篩選出符合閥值的新詞後，透過 1. 新增專有名詞 2. 去除停用詞（雜緒）3. 去除 jieba 本就可以分出的詞，我們可以得到一個新詞字典，再進行斷詞結果的更新。</p><p>實作上面流程，的確可以分出 Jieba 無法擷取的詞 → 好市多、狗狗、詹姆斯、分科測驗、繁星推薦、高股息、熱身賽<br>但實際上還是會有許多的雜訊，例如：的事情、的投資、的東西、的球員，<br>優化幅度不大，少不了人工調整指標參數與去除雜訊的工，目前無法如想像中的自動化。</p><h2 id="心得與回顧"><a href="#心得與回顧" class="headerlink" title="心得與回顧"></a>心得與回顧</h2><p>本文介紹了三點：</p><ol><li>斷詞技術與工具，包含 BIES 標記法、HMM 等，以及常見套件有 jieba、ckip、ckip_transformer、Articut 等。</li><li>斷詞常見的痛有：1. 切法不一（歧義）2. 未知詞問題</li><li>斷詞斷不好怎麼辦：1. 換個工具說不定海闊天空 2. 新增領域專有名詞 3. 凝結度 x 自由度</li></ol><p>斷詞的坑很深，尤其在新詞偵測的部分，很難有一種方法是真的夠好，<br>更常是結合上述所有作法，並參雜不少的人工成本進行梳理、降噪。</p><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p><a href="http://www.matrix67.com/blog/archives/5044">互联网时代的社会语言学：基于SNS的文本数据挖掘</a><br><a href="https://medium.com/@jimmywu0621/%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86-%E6%96%B0%E8%A9%9E%E5%81%B5%E6%B8%AC-f010a38ae5d5">《自然語言處理》新詞偵測. 5p | by JimmyWu</a><br><a href="https://www.youtube.com/watch?v=3HA1jTuKMxg">線上讀書會 - 文立 主講 中文斷詞-結巴</a></p>]]></content>
      
      
      <categories>
          
          <category> nlp </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Building Tweet Classification Models with BERT 🤗</title>
      <link href="/2024/04/17/bert-cls/"/>
      <url>/2024/04/17/bert-cls/</url>
      
        <content type="html"><![CDATA[<p>文本分類是最初接觸 NLP 領域大概最先會碰到的任務類型，其中傳統的做法會使用詞頻、TF-IDF、Word2vec 等方法將文本項量化後再接 SVM, XGBoost 等分類器進行實作。隨著 Transformers 架構出現，大家開始嘗試使用 BERT 等模型來進行文本分類，並且得到不錯的結果，而隨著開源社群的茁壯貢獻，現在想要調用 Bert 進行推理、訓練都已經不是難事，今天以 Hugging Face 的 transformers 套件來進行實作。<br>所以今天的 Tutorial 為實作以 Bert 進行文本分類，其中用到的資料集為來自 Kaggle 公開競賽「<a href="https://www.kaggle.com/competitions/nlp-getting-started">Natural Language Processing with Disaster Tweets</a>」，競賽目的希望透過人們在 X 上的推文預測內容是否正在描述災難（disaster）的情況。</p><p>🤗 你將在本篇文了解：</p><ul><li>如何從 Hugging Face 載入各種大型語言模型</li><li>transformers、Tokenizer、Dataset 功能與使用方法</li><li>如何使用 Trainer API 微調模型</li></ul><h2 id="requirements"><a href="#requirements" class="headerlink" title="requirements"></a>requirements</h2><p>💻 資料集：<a href="https://www.kaggle.com/competitions/nlp-getting-started">kaggle Link</a><br><i class="ffab fa-github"></i> 程式碼：<a href="https://github.com/hsiehbocheng/natural-language-processing-with-disaster-tweets?tab=readme-ov-file">Github Link</a></p><p>筆者套件版本：<br>🐍 python 3.7+<br>🐍 torch 2.1.1<br>🤗 transformers 4.28.0<br>🤗 datasets 2.13.1</p><p>在訓練時我是直接於 Colab 環境執行，使用 A100 GPU，所以套件的部分直接 <code>pip</code> 即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!pip install transformers</span><br><span class="line">!pip install datasets evaluate accelerate</span><br></pre></td></tr></table></figure><h2 id="Data-Description"><a href="#Data-Description" class="headerlink" title="Data Description"></a>Data Description</h2><p>資料集包含推文 id, keyword, location 與 text 以及 target，text 為推文內容，是我們主要要使用的資料，而 target 則是要預測的分類標籤，分別為 0 (not disaster) 和 1 (disaster)。<br><img src="data.png" width="100%"></p><p>在任何任務中資料清洗都是很重要的一環，我想 DS 大約有 80% 的時間都花在資料清洗、資料工程這種下水道工程之中。了解資料，知道資料有什麼異常、分佈需要花費非常多的時間，礙於文章篇幅，這邊在 <a href="https://github.com/hsiehbocheng/natural-language-processing-with-disaster-tweets?tab=readme-ov-file">Github</a> 提供程式與清洗後的資料集，其中資料清洗主要參考了「<a href="https://www.kaggle.com/code/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert">NLP with Disaster Tweets - EDA, Cleaning and BERT</a> 」，作者對資料做了很深入的研究與清洗，包含還原縮寫、亂碼等，也糾正了標記錯誤的資料。我將作者用來做 <code>re.sub</code> 的內容統整到 <code>clean_mapping.xlsx</code> 中，並將處理完的資料放在 repo 中，可直接下載，接下來將會使用這份清洗過的資料。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_train = pd.read_excel(<span class="string">&#x27;./data/df_train.xlsx&#x27;</span>)</span><br><span class="line">df_test = pd.read_excel(<span class="string">&#x27;./data/df_text.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="BERT-訓練"><a href="#BERT-訓練" class="headerlink" title="BERT 訓練"></a>BERT 訓練</h2><h3 id="Hugging-Face-DistilBERT-Introuduciton"><a href="#Hugging-Face-DistilBERT-Introuduciton" class="headerlink" title="Hugging Face &amp; DistilBERT Introuduciton"></a>Hugging Face &amp; DistilBERT Introuduciton</h3><p>雖然說是 BERT，但其實我所使用的是 <a href="https://huggingface.co/distilbert/distilbert-base-uncased?text=The+goal+of+life+is+%5BMASK%5D.">DistilBERT</a>，該模型是 Hugging Face 在 2019 所提出的論文，該架構與 Bert 相似，是利用蒸餾技術降低模型大小，在保有一定準確度下提升模型訓練速度，對於細節有興趣的可以參考<a href="https://arxiv.org/abs/1910.01108">這篇論文</a>。但在 transformers 中使用這兩個模型的差異只在於指定的模型確認站 checkpoint 不一樣而已。</p><p>微調步驟大致為以下：</p><ol><li>將資料轉為 <code>Dataset</code> 格式</li><li>建立 <code>Tokenizer</code> 並將資料轉換成 <code>input_ids</code></li><li>利用 <code>datasets.load_metrc</code> 定義模型訓練評估指標</li><li>建立 <code>Trainer</code> 開始微調模型</li><li>將儲存好的模型與 tokenizer chekpoint 匯出</li></ol><p>其中使用的模型為 Hugging face 的 Models，可以直接至 <a href="https://huggingface.co/">🤗 Hugging Face Hub</a> 搜尋想要的模型，例如我們今天所使用的模型: distilbert&#x2F;distilbert-base-uncased，<br><img src="distilbert.png" width="100%"></p><p>在 Model card 中可以看到模型的簡介以及下載使用的方法，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line">unmasker = pipeline(<span class="string">&#x27;fill-mask&#x27;</span>, model=<span class="string">&#x27;distilbert-base-uncased&#x27;</span>)</span><br><span class="line">unmasker(<span class="string">&quot;Hello I&#x27;m a [MASK] model.&quot;</span>)</span><br></pre></td></tr></table></figure><p>右側有 Inference API 提供模型 Demo 的使用。如果想知道到底有什麼模型可以使用的話，也可以點擊主頁上方的 Models，左側可以依據 Tasks 選取，例如 Natural Labguage Processing 的 Text Classification 或是 Question Answering 等等。<br><img src="hf_models.png" width="100%"></p><h3 id="Data-Preprocessing：Tokenization-Dataset"><a href="#Data-Preprocessing：Tokenization-Dataset" class="headerlink" title="Data Preprocessing：Tokenization &amp; Dataset"></a>Data Preprocessing：Tokenization &amp; Dataset</h3><h4 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h4><p><a href="https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt">🤗 Transformers Tokenizer</a></p><p>先介紹相對重要的 Tokenization 概念。<br><strong>Tokenizer</strong> 中文叫分詞器，主要功能為將文字轉為數字序列，例如將「我愛你」轉為 [2057, 1014, 1012]，其中 2057 代表「我」的索引，1014 代表「愛」的索引，1012 代表「你」的索引。其中涉及到 1. 如何斷詞 2. 轉為數字序列。</p><p>斷詞的方法有很多，例如在英文中可以使用 <code>split()</code> 以空格<strong>基於單字（Word-based）</strong>切割，或是中文常以 <strong>jieba</strong> 進行斷詞。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tokenized_text = <span class="string">&quot;Jim Henson was a puppeteer&quot;</span>.split()</span><br><span class="line"><span class="built_in">print</span>(tokenized_text)</span><br><span class="line">&gt;[<span class="string">&#x27;Jim&#x27;</span>, <span class="string">&#x27;Henson&#x27;</span>, <span class="string">&#x27;was&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;puppeteer&#x27;</span>]</span><br></pre></td></tr></table></figure><p>盤出所有斷詞結果後會建立一個詞彙表 vocabulary，將所有可能出現的詞賦予獨立的 ID 索引，提供模型識別每個單字，其中也會有模型訓練中可能會需要的特殊字詞，例如 [UNK] 代表詞彙表中沒有出現過的字，還有如 [CLS]、[SEP] 等，而這些 ID，或是所謂斷詞後的字，我們將稱作為 <code>token</code>。其他例如 charactor-based、subwork-based 等也是常見的斷詞技術，而在 LLM 中更常見的如 GPT-2 所使用的 <strong>Byte-level BPE</strong>、BERT 使用的 <strong>WordPiece</strong> 或是 <strong>SenetencePiece</strong> 等。</p><p>而從上述介紹，可以想像不同的模型所使用的 Tokenizer 很容易會有所不同，基於訓練資料、語言等等，因此在 transformers 中，我們會設定想要載入的模型 checkpoint，例如 <code>Google/BERT</code>，同時載入相對應的模型權重與 Tokenizer，如此就會將剛剛我提到的 vocabulay 與其他需要資料下載下來。</p><p>在 transformers 中，我們可以透過兩種方法載入 Tokenizer：</p><ol><li>指定 Tokenizer 名稱， <code>from transformers import DistilBertTokenizer</code>  </li><li>使用 <code>AutoTokenizer</code> ，自動偵測並載入對應 checkpoint 的 tokenizer，<br>我們將 checkpoint 指定給 <code>AutoTokenizer</code>，調用 <code>.from_pretrained()</code> 即可，其中 checkpoint 為模型名稱則為從 <a href="https://huggingface.co/">Hugging Face</a> 下載，或是直接指定到本地端的模型路徑。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">checkpoint = <span class="string">&quot;distilbert-base-uncased&quot;</span> <span class="comment"># huggingface checkpoint</span></span><br><span class="line"><span class="comment"># checkpoint = &quot;./model/your_local_checkpoint_path&quot; # local checkpoint</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(checkpoint)</span><br></pre></td></tr></table></figure><p>tokenizer 中我們可以利用以下 function 做分詞相關操作：<br><code>.tokenize()</code> 將文本進行斷詞<br><code>.convert_tokens_to_ids()</code> 將斷詞結果轉為 ID 序列<br><code>.decode()</code> 將 ID 序列還原為 token 文字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">text = df_train[<span class="string">&#x27;text_cleaned&#x27;</span>].iloc[<span class="number">0</span>]</span><br><span class="line">tokens = tokenizer.tokenize(text)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;斷詞結果：<span class="subst">&#123;tokens&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">ids = tokenizer.convert_tokens_to_ids(tokens)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分詞 id 序列: <span class="subst">&#123;ids&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">decoded_string = tokenizer.decode(ids)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;decode 還原：<span class="subst">&#123;decoded_string&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;斷詞結果：[&#x27;our&#x27;, &#x27;deeds&#x27;, &#x27;are&#x27;, &#x27;the&#x27;, &#x27;reason&#x27;, &#x27;of&#x27;, &#x27;this&#x27;, &#x27;#&#x27;, &#x27;earthquake&#x27;, &#x27;may&#x27;, &#x27;allah&#x27;, &#x27;forgive&#x27;, &#x27;us&#x27;, &#x27;all&#x27;]</span><br><span class="line">&gt;分詞 id 序列: [2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035]</span><br><span class="line">&gt;decode 還原：our deeds are the reason of this # earthquake may allah forgive us all</span><br></pre></td></tr></table></figure><p>其中在 tokenizer 有 <code>padding</code>, <code>truncation</code>, <code>max_length</code> 參數以供設定，細節可看 <a href="https://huggingface.co/docs/transformers/pad_truncation">Padding and truncation</a>。</p><p>最後，我們直接 call 實體化後的分詞器進行分詞（推薦）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result = tokenizer(text,</span><br><span class="line">                   return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;result: <span class="subst">&#123;result&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tokenizer.decode(result[<span class="string">&#x27;input_ids&#x27;</span>][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;result: &#123;&#x27;input_ids&#x27;: tensor([[  101,  2256, 15616,  2024,  1996,  3114,  1997,  2023,  1001,  8372,</span><br><span class="line">          2089, 16455,  9641,  2149,  2035,   102]]), &#x27;attention_mask&#x27;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])&#125;</span><br><span class="line">&gt;[CLS] our deeds are the reason of this # earthquake may allah forgive us all [SEP]</span><br></pre></td></tr></table></figure><p>如此一來我們完成了分詞的操作，接下來要做的是將其包裝成一個 function 讓我們可以直接對所有資料及進行分詞。</p><h4 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h4><p><a href="https://huggingface.co/docs/datasets/index">🤗 Transformers Datasets</a><br>如同使用 PyTorch 時，我們需要 <code>torch.utils.data.Dataset</code> 將我們的資料包裝起來，並透過 <code>torch.utils.data.DataLoader</code> 定義每一次 Batch 的抽樣參數，在 transformers 中，我們利用 <code>Datasets</code> 定義載入資料的方法，包裝成 datasets 資料格式，<code>Dataset</code> 在 Apache Arrow 格式的支援下，再處理大型資料及上獲得更快的效率與速度。</p><p>我們想要做的事是將載進來的 <code>pd.Dataframe</code> 轉為 <code>Datasets</code> 並且對所資料進行 tokenizer，<br>所以我們需要：</p><ol><li>定義 <code>tokenizer</code> function</li><li>將 <code>pd.Dataframe</code> 轉為 <code>Dataset</code>，並且透過 <code>map</code> 與 <code>batched=True</code> 快速地將資料進行分詞。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_tokenizer</span>(<span class="params">data: Dataset</span>):</span><br><span class="line">  <span class="keyword">return</span> tokenizer(data[<span class="string">&quot;text_cleaned&quot;</span>],</span><br><span class="line">                   truncation=<span class="literal">True</span>,</span><br><span class="line">                   )</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train, dev, test split</span></span><br><span class="line">df_trian, df_dev = train_test_split(df_train, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform to dataset</span></span><br><span class="line">ds_train = Dataset.from_pandas(df_train)</span><br><span class="line">ds_dev = Dataset.from_pandas(df_dev)</span><br><span class="line">ds_test = Dataset.from_pandas(df_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ds_train = ds_train.<span class="built_in">map</span>(do_tokenizer, batched=<span class="literal">True</span>)</span><br><span class="line">ds_dev = ds_dev.<span class="built_in">map</span>(do_tokenizer, batched=<span class="literal">True</span>)</span><br><span class="line">ds_test = ds_test.<span class="built_in">map</span>(do_tokenizer, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>如此一來我們已經將資料中的 text 欄位透過 tokenizer 轉為分詞後的 input_ids 序列，我們接下來要做的最後一件事情是將所有的資料長度填充到一樣長，可以看到下方，我們列出前 10 筆資料的 input_ids 長度，可以發現其實有些序列長度不同。所以我們要做的事是，依據文本中最長的序列長度，將其他序列補齊到相同長度，這種手法叫做 <code>padding</code>，可以看到下方，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="built_in">len</span>(input_ids) <span class="keyword">for</span> input_ids <span class="keyword">in</span> ds_train[:<span class="number">10</span>][<span class="string">&#x27;input_ids&#x27;</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;[16, 12, 27, 14, 22, 29, 20, 21, 15, 16, 11]</span><br></pre></td></tr></table></figure><p>而我們要使用的 padding 方法是 Dynamic Padding 動態補長，透過 <code>DataCollatorWithPadding</code> 進行設定實作，<br>為什麼要動態補長呢？如果依據整個資料集的最長序列進行補齊，可能會浪費掉太多不必要的空間與運算時間，我們其實只需要模型每一次的輸入中，確保各自 batch 間的序列長度一樣即可，所以透過 <code>DataCollatorWithPadding</code>，抽取 batch 時進行 padding，這將為加速訓練時的速度。（注意：這種作法可能會導致在 TPU 上產生錯誤，TPU 更偏好資料為固定長度）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorWithPadding</span><br><span class="line"></span><br><span class="line"><span class="comment"># 動態 padding</span></span><br><span class="line">data_collator = DataCollatorWithPadding(tokenizer=tokenizer)</span><br></pre></td></tr></table></figure><p>最後的最後，我們將不需要的欄位去除、重新命名，並定義 label 對應的標籤，即可開使進行訓練了！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">col2remove = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;keyword&#x27;</span>, <span class="string">&#x27;location&#x27;</span>, <span class="string">&#x27;text&#x27;</span>]</span><br><span class="line"></span><br><span class="line">ds_train = ds_train.remove_columns(col2remove)</span><br><span class="line">ds_dev = ds_dev.remove_columns(col2remove)</span><br><span class="line">ds_test = ds_test.remove_columns(col2remove)</span><br><span class="line"></span><br><span class="line">ds_train = ds_train.rename_column(<span class="string">&quot;target_relabeled&quot;</span>, <span class="string">&quot;label&quot;</span>)</span><br><span class="line">ds_dev = ds_dev.rename_column(<span class="string">&quot;target_relabeled&quot;</span>, <span class="string">&quot;label&quot;</span>)</span><br><span class="line"></span><br><span class="line">id2label = &#123;<span class="number">0</span>: <span class="string">&quot;NOT&quot;</span>,</span><br><span class="line">            <span class="number">1</span>: <span class="string">&quot;YES&quot;</span>&#125;</span><br><span class="line">label2id = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> id2label.items()&#125;</span><br></pre></td></tr></table></figure><h3 id="Fine-tune-with-Trainer-API"><a href="#Fine-tune-with-Trainer-API" class="headerlink" title="Fine tune with Trainer API"></a>Fine tune with Trainer API</h3><p><a href="https://huggingface.co/docs/transformers/main_classes/trainer">🤗 Transformers Trainer API</a></p><p>transformers 提供 <code>Trainer</code> 進行資料的微調，只需要簡單的幾步驟設定，即可快速使用 <code>Trainer.train()</code> 開始訓練，而不用自己寫 training loop。</p><h4 id="How-to-donwload-models"><a href="#How-to-donwload-models" class="headerlink" title="How to donwload models"></a>How to donwload models</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, TrainingArguments, Trainer</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_metric</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(</span><br><span class="line">    checkpoint,</span><br><span class="line">    num_labels=<span class="number">2</span>,</span><br><span class="line">    id2label=id2label,</span><br><span class="line">    label2id=label2id</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>訓練前，我們要載入模型的 pretrained weights，與 Tokenizer 下載方法雷同，我們可以直接指定 checkpoint 利用 <code>.from_pretrained()</code> 進行下載，比較不一樣的是，雖然是使用 <code>AutoClass</code> 方法建立，<br>但我們會依據不同的 task 使用不同的 <code>AutoClass</code>，例如我們這次要做的是分類任務，就會是 <code>AutoModelForSequenceClassification</code>。</p><p>模型將依據不同的任務，自動在載入模型後將模型架構改為適合該任務的架構，例如分類任務會在最後新增一層依據分類類別個數而定義的分類層，而依據任務而新增的神經層權重會是隨機初始化的，可以從下載模型後的 Warning 看到：</p><blockquote><p>Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [‘classifier.weight’, ‘pre_classifier.bias’, ‘classifier.bias’, ‘pre_classifier.weight’]<br>You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</p></blockquote><p>最後有興趣的話，我們可以在 <a href="https://huggingface.co/transformers/v3.0.2/model_doc/auto.html">這裏</a> 看到還有什麼 <code>AutoClass</code>。</p><h4 id="Where-the-weights-is-saved"><a href="#Where-the-weights-is-saved" class="headerlink" title="Where the weights is saved"></a>Where the weights is saved</h4><p>下載好的權重預設會處存在快取資料夾中， <code>~/.cache/huggingface/transformers/</code>，所以再次調用 <code>.from_pretrained()</code> 會預設從該資料夾進行下載，如果沒有找到資料才會從網路上下載，故使用 colab 如果斷線的話，是要重新下載權重的，而如果想更改預設儲存路徑的話，可以透過環境變數 <code>HF_HOME</code> 進行設定。</p><h4 id="How-to-save-the-model"><a href="#How-to-save-the-model" class="headerlink" title="How to save the model"></a>How to save the model</h4><p>保存模型就如同載入模型，我們使用 <code>.save_pretrained()</code> 即可，但需要指定 <code>output_dir</code> 來指定模型儲存的位置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output_dir = <span class="string">&quot;directory_on_my_computer&quot;</span></span><br><span class="line">model.save_pretrained(output_dir)</span><br></pre></td></tr></table></figure><p>將會有兩份文件被處存，1. <code>config.json</code> 保存模型的設定，2. <code>pytorch_model.bin</code> 保存模型的權重。</p><h3 id="Setting-the-Trainer-arguments"><a href="#Setting-the-Trainer-arguments" class="headerlink" title="Setting the Trainer arguments"></a>Setting the Trainer arguments</h3><h4 id="TrainingArguments"><a href="#TrainingArguments" class="headerlink" title="TrainingArguments"></a>TrainingArguments</h4><p>定義 Trainer 之前要先定義 TraingArguments，這些參數包含了控制訓練的各種設定，其中必須提供的參數是保存參數的路徑，其餘的設定可以使用預設，也可以自己嘗試調整以優化模型，例如我列出了一些常用的參數：</p><ul><li><code>seed</code>：設定隨機種子，用來產生隨機數，以便於重現結果</li><li><code>learning_rate</code>：設定學習率</li><li><code>per_device_train_batch_size</code>：設定每個 GPU 的訓練 batch size</li><li><code>eval_steps</code>：設定模型經過多少 steps 進行評估</li><li><code>save_steps</code>：設定模型經過多少 steps 進行保存</li><li><code>evaluation_strategy</code>：設定評估策略，可以選擇 <code>steps</code> 或 <code>epoch</code>，</li></ul><p>其中 <code>evaluation_strategy</code> 有別於 early stopping，我們透過這個參數，在模型訓練結束後，會依據所選的 steps 或是 epoch 處存的模型，自動去找到最好的模型。</p><p>想看更多 <code>TrainingArguments</code> 的細節可以在 <a href="https://huggingface.co/docs/transformers/v4.39.3/en/main_classes/trainer#transformers.TrainingArguments">這裡</a> 找到</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir = <span class="string">&#x27;./model/&#x27;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    seed=<span class="number">11</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>,</span><br><span class="line">    per_device_eval_batch_size=<span class="number">16</span>,</span><br><span class="line">    num_train_epochs=<span class="number">4</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">    eval_steps=<span class="number">600</span>,</span><br><span class="line">    save_steps=<span class="number">600</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">    save_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="Comput-Metrics"><a href="#Comput-Metrics" class="headerlink" title="Comput Metrics"></a>Comput Metrics</h4><p>訓練模型中，我們需要評估指標來告訴我們目前模型的表現如何，在 Datasets 中，提供了各種 NLP 常見的指標，可以使用 <code>list_metrics()</code> 查看有哪些指標可以使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> list_metrics</span><br><span class="line">metrics = list_metrics()</span><br><span class="line"><span class="built_in">print</span>(metrcs_list)</span><br><span class="line">&gt;[<span class="string">&#x27;accuracy&#x27;</span>, <span class="string">&#x27;bertscore&#x27;</span>, <span class="string">&#x27;bleu&#x27;</span>, <span class="string">&#x27;bleurt&#x27;</span>, <span class="string">&#x27;cer&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;comet&#x27;</span>, <span class="string">&#x27;coval&#x27;</span>, <span class="string">&#x27;cuad&#x27;</span>, <span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;gleu&#x27;</span>, <span class="string">&#x27;glue&#x27;</span>, <span class="string">&#x27;indic_glue&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;matthews_correlation&#x27;</span>, <span class="string">&#x27;meteor&#x27;</span>, <span class="string">&#x27;pearsonr&#x27;</span>, <span class="string">&#x27;precision&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;recall&#x27;</span>, <span class="string">&#x27;rouge&#x27;</span>, <span class="string">&#x27;sacrebleu&#x27;</span>, <span class="string">&#x27;sari&#x27;</span>, <span class="string">&#x27;seqeval&#x27;</span>, <span class="string">&#x27;spearmanr&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;squad&#x27;</span>, <span class="string">&#x27;squad_v2&#x27;</span>, <span class="string">&#x27;super_glue&#x27;</span>, <span class="string">&#x27;wer&#x27;</span>, <span class="string">&#x27;wiki_split&#x27;</span>, <span class="string">&#x27;xnli&#x27;</span>]</span><br></pre></td></tr></table></figure><p>我們可以使用 <code>load_metric()</code> 從 Hub 中載入指標，可以直接指定 <code>metric = load_metric(&#39;accuracy&#39;)</code> 也可以自定義技術函數，在此之前我們需要先了解 metric 回傳的資訊有什麼，可以從 <a href="https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/main_classes#datasets.MetricInfo">datasets.MetricInfo</a> 得到更多的細節。</p><p>metric 以 <code>.comput()</code> 方法計算 <code>predictions</code> 與 <code>referece</code> 之間的分數，並回傳字典，字典的 key 為 metric 名稱，value 為計算的分數，所以我們如果想要自定義計算方法的話，記得要回傳字典格式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_metrics</span>(<span class="params">eval_pred</span>):</span><br><span class="line">    load_acc = load_metric(<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">    load_f1 = load_metric(<span class="string">&#x27;f1&#x27;</span>)</span><br><span class="line">    logits,labels = eval_pred</span><br><span class="line">    predictions = np.argmax(logits,axis = -<span class="number">1</span>)</span><br><span class="line">    acc = load_acc.compute(predictions = predictions,references = labels)[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">    f1 = load_f1.compute(predictions = predictions, references = labels)[<span class="string">&#x27;f1&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;acc&#x27;</span>:acc,<span class="string">&#x27;f1&#x27;</span>:f1&#125;</span><br></pre></td></tr></table></figure><p>經過以上步驟，我們已經完成了訓練前的前置作業，包含</p><ol><li>tokenizer 進行分詞</li><li>將資料轉為 Dataset</li><li>定義 compute_metrics 計算指標</li><li>定義 TrainingArguments 設定訓練參數</li></ol><p>最後我們只需要實體化 Trainer，並將這些資料與參數傳入即可開始訓練！</p><h4 id="the-last-but-not-the-least-Train"><a href="#the-last-but-not-the-least-Train" class="headerlink" title="the last but not the least, Train!"></a>the last but not the least, Train!</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=ds_train,</span><br><span class="line">    eval_dataset=ds_dev,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    compute_metrics=compute_metrics,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure><p>這就開始微調訓練了！並且在訓練期間會依據我們設定的 step 對驗證集進行驗證告訴我們目前模型表現狀況，且儲存模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pred = trainer.predict(ds_dev)</span><br><span class="line">pred = np.argmax(pred.predictions, axis=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>訓練完畢後我們可以直接對 Trainer 調用 <code>.predict()</code> 函數，傳入測試集，得到模型預測的結果。</p><p>以上就完成 Bert 進行分類任務訓練微調啦 🎉</p><p>這次的介紹為簡單帶過整個流程，如果想知道更多的細節可以看 Hugging Face 的官方文件，其實寫得非常完整，也有針對各字模組做相關的教學，非常推薦！<br> <a href="https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt">官方教學在這裡！</a></p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://huggingface.co/learn/nlp-course/chapter1/1">🤗 Hugging Face NLP Course</a><br><a href="https://www.kaggle.com/code/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert">NLP with Disaster Tweets - EDA, Cleaning and BERT</a></p>]]></content>
      
      
      <categories>
          
          <category> nlp </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> nlp </tag>
            
            <tag> bert </tag>
            
            <tag> hugging face </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dive into Multithreading in Python!</title>
      <link href="/2024/04/16/multithreading/"/>
      <url>/2024/04/16/multithreading/</url>
      
        <content type="html"><![CDATA[<p>隨著寫程式經驗越來越多，我們開始會碰到一些需要等待一段時間才能完成任務，<br>例如 1. 利用 API 或是 request 批量下載大量資料 2. 需要大量使用 CPU 進行數學運算的工作。<br>這時候我們就可以考慮是否適合使用平行運算技術進行加速。常見的有多線程（multithreading）以及多進程（multiprocessing）。<br>本文主要介紹以下三點：</p><ol><li>多進程與多線程的差異</li><li>Python 實作多線程 </li><li>以多線程改寫加速現有爬蟲程式</li></ol><h2 id="What-are-Multiprocessing-and-Multithreading"><a href="#What-are-Multiprocessing-and-Multithreading" class="headerlink" title="What are Multiprocessing and Multithreading?"></a>What are Multiprocessing and Multithreading?</h2><h3 id="Difference-between-process-and-threads"><a href="#Difference-between-process-and-threads" class="headerlink" title="Difference between process and threads"></a>Difference between process and threads</h3><p>首先，什麼是進程 Process？什麼是執行緒 Threads？如果讀者是使用的 Mac 的話，可以在「活動監視器」的 CPU 中，看到右下角呈現目前執行的執行緒與程序數量。</p><img src="/2024/04/16/multithreading/activity.png" class=""><ul><li>Process 簡單來說進程就是正在運行中的程式，例如 App, 軟體等。</li><li>Thread 則是在 Process 運行中，因為需要同時進行運算、介面互動、資料庫搜索等工作，這些任務即可稱作執行緒 Threads。</li></ul><p>Process 就像一間工廠，其中有需多的工具（Files, Data），而 Threads 則為工人，Multiprocessing 代表就多間工廠，各自使用自家的工人（Threads）與工具（Files, Data），而 Multithreading 則像是一間工廠中娉請多個工人加速工廠的產能。</p><p>所以多進程 Multiprocessing 代表系統同時運行多個軟體，而多線程 Multithreading 則代表一個 Process 中同時執行多個執行緒的能力。<br><img src="compare.png" width="100%"></p><p>其中多線程與多進程的差異在於，多線程在一個程序中執行多個執行緒進行不同任務，這些任務的開始時間幾乎同時，並且一個接一個的進行，這會提供一種同時運行的錯覺，但其實並沒有。<br>而多進程則是以多個 Processes 在多個 CPU 上執行達到真正意義上的平行運算，而這些核心之間並不共享各自的資源，<br>例如下圖所示，當我今天有一個 func 會運行兩次，其中執行一次時間大約 1 秒，執行運行兩次時間大約 2 秒，而使用 Multithreading 與 Multiprocessing 差異則在於這兩個 func 是否真正的同時並行處理。</p><img src="/2024/04/16/multithreading/compare2.png" class=""><h3 id="CPU-Bound-and-I-O-Bound-Tasks"><a href="#CPU-Bound-and-I-O-Bound-Tasks" class="headerlink" title="CPU Bound and I&#x2F;O Bound Tasks"></a>CPU Bound and I&#x2F;O Bound Tasks</h3><p>上面提到會需要執行很久的任務可大致分為兩種情形，需要大量的運算或是從硬碟、網路存取寫入大量的資料，其中，</p><ul><li>CPU Bound 代表高度仰賴 CPU 運算的任務，例如圖片處理、數學運算、機器學習等。</li><li>I&#x2F;O Bound 代表這個工作的等待時間主要在於資料的存取，例如爬蟲、從硬碟載資料，而這部分的操作則不太需要 CPU 的參與。</li></ul><p>Multithreading 就非常適合加速 I&#x2F;O Bound 的任務，將需要載入寫出的資料分配給多個執行緒，<br>就像是我們在網路上下載照片、影片等等，我們不會一起載一張，載好再載下一張，我們一定都是點完所有的下載連接，再等各自資料一一載完。<br>但在 Python 會受到 Global Interprter Lock, GIL 特性的影響，GIL 限制 Python 解釋器同時只能有一個 Python 字節碼執行，為了避免執行緒間數據競爭的問題，<br>在 CPU Bound 任務中，CPU 核心不斷地切換執行緒，但只有一個執行緒能夠執行 Python 代碼使得其他執行緒處於等待時間，而浪費 CPU 時間，<br>所以在 CPU Bound 任務上，更常會使用 Multiprocessing，利用多個 Processor 加速運算。</p><h2 id="Let’s-Get-Practical-Multithreading-in-Python"><a href="#Let’s-Get-Practical-Multithreading-in-Python" class="headerlink" title="Let’s Get Practical: Multithreading in Python!"></a>Let’s Get Practical: Multithreading in Python!</h2><p>Multithreading 可以使用 Python 標準庫 <code>threading</code> 實現，主要流程有以下：</p><ol><li>Create Thread：分配執行的任務，也就是 Python function 給每個執行緒</li><li>Start Execution：執行緒開始執行任務</li><li>Wait for the thread to complete execution：當我們在第二步開始執行後，如果沒有設置檢查點，程式會直接運行接下來的程式，所以我們需要設置檢查點，等待執行緒完成任務才往後運行後續程式。</li></ol><h3 id="Without-multithreading"><a href="#Without-multithreading" class="headerlink" title="Without multithreading"></a>Without multithreading</h3><p>以下程式定義了一個 function <code>load_data_from_somewhere()</code>，模擬一個下載資料的程式，其中接受一個參數 <code>need_sec</code> 代表這個函數需要執行多久，模擬下載的時間。<br>我們利用迴圈將 <code>load_data_from_somewhere</code> 運行兩次，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.perf_counter()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_from_somewhere</span>(<span class="params">need_sec=<span class="number">1</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Downloading ...&#x27;</span>)</span><br><span class="line">    time.sleep(need_sec)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Done! it takes <span class="subst">&#123;need_sec&#125;</span> second(s)&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> _  <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    load_data_from_somewhere()</span><br><span class="line"></span><br><span class="line">finish = time.perf_counter()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Total Cost <span class="subst">&#123;<span class="built_in">round</span>(finish-start, <span class="number">2</span>)&#125;</span> second(s)&#x27;</span>)</span><br></pre></td></tr></table></figure><p>輸出會如下，依序運行了兩次，總共花費兩秒。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Downloading ...</span><br><span class="line">Done! it takes 1 second(s)</span><br><span class="line">Downloading ...</span><br><span class="line">Done! it takes 1 second(s)</span><br><span class="line">---</span><br><span class="line">Total Cost 2.01 second(s)</span><br></pre></td></tr></table></figure><h3 id="Speeding-up-by-Threading"><a href="#Speeding-up-by-Threading" class="headerlink" title="Speeding up by Threading"></a>Speeding up by Threading</h3><p>接下來我們載入 <code>threading</code>，還記得我們上面提到使用多線程的流程嗎？</p><ol><li>Create Thread：透過 <code>theading.Thread</code> 創建執行緒，並透過 <code>target</code> 指定執行的任務</li><li>Start Execution：<code>.start()</code></li><li>Wait for the thread to complete execution：<code>.join()</code></li></ol><p>在下面程式中，我創建了兩個執行緒並命名為 worker1, worker2，一樣是執行兩次下載資料的函示，發現這次只需要 1.01 秒了！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line">start = time.perf_counter()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_from_somewhere</span>(<span class="params">need_sec=<span class="number">1</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Downloading ...\n&#x27;</span>)</span><br><span class="line">    time.sleep(need_sec)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Done! it takes <span class="subst">&#123;need_sec&#125;</span> second(s)\n&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Create Thread</span></span><br><span class="line">worker1 = threading.Thread(target=load_data_from_somewhere)</span><br><span class="line">worker2 = threading.Thread(target=load_data_from_somewhere)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start Execution Execution</span></span><br><span class="line">worker1.start()</span><br><span class="line">worker2.start()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Wait for the thread to complete execution</span></span><br><span class="line">worker1.join()</span><br><span class="line">worker2.join()</span><br><span class="line"></span><br><span class="line">finish = time.perf_counter()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Total Cost <span class="subst">&#123;<span class="built_in">round</span>(finish-start, <span class="number">2</span>)&#125;</span> second(s)&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># output</span><br><span class="line"></span><br><span class="line">Downloading ...</span><br><span class="line"></span><br><span class="line">Downloading ...</span><br><span class="line"></span><br><span class="line">Done! it takes 1 second(s)</span><br><span class="line">Done! it takes 1 second(s)</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">Total Cost 1.01 second(s)</span><br></pre></td></tr></table></figure><h3 id="High-level-API-concurrent-futures"><a href="#High-level-API-concurrent-futures" class="headerlink" title="High level API concurrent.futures"></a>High level API concurrent.futures</h3><p><a href="https://docs.python.org/3/library/concurrent.futures.html">concurrent.futures</a> 是一個很方便的高級 API 幫助我們更快速地實現多進程與多線程，<br>使用 <code>ThreadPoolExectuor</code>，透過 <code>submit</code> 給予任務即可。</p><p>在以下的程式我做了三件事情，</p><ol><li>透過 <code>spleep_list</code> 動態以 <code>**kwargs</code> 或是 <code>*args</code> 傳入 <code>load_data_from_somewhere</code> 需要的參數。</li><li>利用 <code>concurrent.futures.ThreadPoolExecutor()</code> 在 with context 以 <code>.submit()</code> 執行多執行緒任務。</li><li>利用迴圈創建多個執行緒。</li></ol><p>共執行了五次 <code>load_data_from_somewhere</code>，耗時只使用了 5 秒鐘。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.perf_counter()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_from_somewhere</span>(<span class="params">need_sec=<span class="number">1</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Downloading ...\n&#x27;</span>)</span><br><span class="line">    time.sleep(need_sec)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Done! it takes <span class="subst">&#123;need_sec&#125;</span> second(s)\n&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">sleep_list = [<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line"><span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">    <span class="keyword">for</span> sec <span class="keyword">in</span> sleep_list:</span><br><span class="line">        executor.submit(load_data_from_somewhere, **&#123;<span class="string">&quot;need_sec&quot;</span>: sec&#125;)</span><br><span class="line">        </span><br><span class="line">finish = time.perf_counter()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Total Cost <span class="subst">&#123;<span class="built_in">round</span>(finish-start, <span class="number">2</span>)&#125;</span> second(s)&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#output</span><br><span class="line">Downloading ...</span><br><span class="line"></span><br><span class="line">Downloading ...</span><br><span class="line"></span><br><span class="line">Downloading ...</span><br><span class="line"></span><br><span class="line">Downloading ...</span><br><span class="line"></span><br><span class="line">Downloading ...</span><br><span class="line"></span><br><span class="line">Done! it takes 1 second(s)</span><br><span class="line"></span><br><span class="line">Done! it takes 2 second(s)</span><br><span class="line"></span><br><span class="line">Done! it takes 3 second(s)</span><br><span class="line"></span><br><span class="line">Done! it takes 4 second(s)</span><br><span class="line"></span><br><span class="line">Done! it takes 5 second(s)</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">Total Cost 5.01 second(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="How-to-get-the-return-value-of-a-function-from-each-thread"><a href="#How-to-get-the-return-value-of-a-function-from-each-thread" class="headerlink" title="How to get the return value of a function from each thread"></a>How to get the return value of a function from each thread</h3><p>可以利用 <code>.result()</code> 得到函數的回傳值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.perf_counter()</span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_from_somewhere</span>(<span class="params">need_sec=<span class="number">1</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Downloading ...\n&#x27;</span>)</span><br><span class="line">    time.sleep(need_sec)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&#x27;Done! it takes <span class="subst">&#123;need_sec&#125;</span> second(s)\n&#x27;</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">sleep_list = [<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line"><span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">    results = [executor.submit(load_data_from_somewhere, **&#123;<span class="string">&quot;need_sec&quot;</span>: sec&#125;) <span class="keyword">for</span> sec <span class="keyword">in</span> sleep_list]</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> concurrent.futures.as_completed(results):</span><br><span class="line">        <span class="built_in">print</span>(f.result())</span><br><span class="line">        </span><br><span class="line">finish = time.perf_counter()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;---&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Total Cost <span class="subst">&#123;<span class="built_in">round</span>(finish-start, <span class="number">2</span>)&#125;</span> second(s)&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="Speeding-up-an-existing-web-scraping-program-by-multithreading"><a href="#Speeding-up-an-existing-web-scraping-program-by-multithreading" class="headerlink" title="Speeding up an existing web scraping program by multithreading"></a>Speeding up an existing web scraping program by multithreading</h3><p>接下來我們嘗試改寫一支現有的爬蟲程式，以多線程進行加速。</p><p>我寫了一支 function 用以抓取聯合新聞網中，即時新聞的即時列表，並以 while 迴圈動態抓取所有 page 的內容，也就是調整網址中的 page 參數，<br>並且將抓取來的內容以 <code>pandas.to_csv()</code> 載回本地硬碟。<br>其中參數：</p><ul><li>cn_page：總共要抓幾篇。</li><li>init_page：從第幾篇開始抓。</li><li>sleep_time：遇到無 response 時睡多久。</li><li>break_times_limit：同一網址抓取不到 Response 幾次則放棄。</li></ul><p>這個任務就符合上述所提到的 I&#x2F;O Bound 任務，主要運行的時間在等待 request 回傳內容以及 sleep 與寫出資料，所以很適合使用 multithreading 進行加速，<br>筆者實測，5000 個 page 原本需要 100+ 分鐘，使用多線程將至 11 分鐘左右。</p><p>爬蟲 function：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_url</span>(<span class="params">cn_page: <span class="built_in">int</span>=<span class="number">10</span>,</span></span><br><span class="line"><span class="params">            init_page: <span class="built_in">int</span>=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">            sleep_time:<span class="built_in">float</span> = <span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">            break_times_limit:<span class="built_in">int</span> = <span class="number">2</span>,</span></span><br><span class="line"><span class="params">            save_dir = <span class="string">&#x27;./data&#x27;</span></span>) -&gt; pd.DataFrame:</span><br><span class="line">    result_list = []</span><br><span class="line">    untrack_page = []</span><br><span class="line">    current = init_page</span><br><span class="line">    break_times = <span class="number">0</span></span><br><span class="line">    pbar = tqdm(desc=<span class="string">f&#x27;while loop init_page:<span class="subst">&#123;init_page&#125;</span>; cn_page: <span class="subst">&#123;cn_page&#125;</span>&#x27;</span>, total=cn_page)</span><br><span class="line">    <span class="keyword">while</span> current &lt; init_page+cn_page <span class="keyword">or</span> break_times &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span>  break_times &gt;= break_times_limit:</span><br><span class="line">            untrack_page.append(current)</span><br><span class="line">            current += <span class="number">1</span></span><br><span class="line">            break_times = <span class="number">0</span></span><br><span class="line">            pbar.update(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url = <span class="string">f&quot;https://udn.com/api/more?page=<span class="subst">&#123;current&#125;</span>&amp;id=&amp;channelId=1&amp;cate_id=99&amp;type=breaknews&amp;totalRecNo=24215&quot;</span></span><br><span class="line">            result = requests.get(url).json()[<span class="string">&#x27;lists&#x27;</span>]</span><br><span class="line">            result_list.extend(result)</span><br><span class="line">            break_times = <span class="number">0</span></span><br><span class="line">            result_df = pd.DataFrame(result)</span><br><span class="line">            result_df.to_csv(<span class="string">f&quot;<span class="subst">&#123;save_dir&#125;</span>/result_page_<span class="subst">&#123;current&#125;</span>.csv&quot;</span>, </span><br><span class="line">                             index=<span class="literal">False</span>,</span><br><span class="line">                             encoding=<span class="string">&#x27;utf_8_sig&#x27;</span></span><br><span class="line">                             )</span><br><span class="line">            current += <span class="number">1</span></span><br><span class="line">            pbar.update(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            break_times += <span class="number">1</span></span><br><span class="line">            time.sleep(sleep_time)</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&#x27;get <span class="subst">&#123;current&#125;</span>+<span class="subst">&#123;cn_page&#125;</span>&#x27;</span></span><br></pre></td></tr></table></figure><p>沒有使用多線程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">num_workers = <span class="number">50</span></span><br><span class="line">cn_page = <span class="number">5000</span></span><br><span class="line">step = <span class="built_in">int</span>(cn_page/num_workers) </span><br><span class="line"></span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> init_page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, cn_page, step):</span><br><span class="line">    get_url(**&#123;<span class="string">&#x27;cn_page&#x27;</span>: step, </span><br><span class="line">                <span class="string">&#x27;init_page&#x27;</span>: init_page&#125;)</span><br></pre></td></tr></table></figure><p>使用多線程（threading）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line">num_workers = <span class="number">50</span></span><br><span class="line">cn_page = <span class="number">5000</span></span><br><span class="line">step = <span class="built_in">int</span>(cn_page/num_workers) </span><br><span class="line"></span><br><span class="line">workers = []</span><br><span class="line"><span class="keyword">for</span> init_page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, cn_page, step):</span><br><span class="line">    worker = threading.Thread(target=get_url,</span><br><span class="line">                            kwargs=&#123;<span class="string">&#x27;cn_page&#x27;</span>: step, </span><br><span class="line">                                    <span class="string">&#x27;init_page&#x27;</span>: init_page&#125;)</span><br><span class="line">    worker.start()</span><br><span class="line">    workers.append(worker)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> worker <span class="keyword">in</span> workers:</span><br><span class="line">    worker.join()</span><br></pre></td></tr></table></figure><p>使用多線程（concurrent.futures）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"></span><br><span class="line">num_workers = <span class="number">50</span></span><br><span class="line">cn_page = <span class="number">5000</span></span><br><span class="line">step = <span class="built_in">int</span>(cn_page/num_workers) </span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">    <span class="keyword">for</span> init_page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, cn_page, step):</span><br><span class="line">        executor.submit(get_url, </span><br><span class="line">                        **&#123;<span class="string">&#x27;cn_page&#x27;</span>: step,</span><br><span class="line">                            <span class="string">&#x27;init_page&#x27;</span>: init_page&#125;)</span><br></pre></td></tr></table></figure><p>此文章同步於 <a href="https://medium.com/@bensonhsieh/dive-into-multithreading-in-python-37aed325f9a2">Medium</a>。<br>也歡迎大家傳送 Linkedin 連結邀請給我。<a href="https://www.linkedin.com/in/%E5%8D%9A%E4%B8%9E-%E8%AC%9D-4396b7235/">Linkedin Profile</a></p><h2 id="Refer"><a href="#Refer" class="headerlink" title="Refer"></a>Refer</h2><p><a href="https://www.geeksforgeeks.org/difference-between-multithreading-vs-multiprocessing-in-python/">GeeksforGeeks.org, Difference Between Multithreading vs Multiprocessing in Python</a><br><a href="https://youtu.be/IEEhzQoKtQU?si=5ihqzqG6NHOxWs9M">Corey Schafer’s Python Threading Tutorial: Run Code Concurrently Using the Threading Module</a></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PySpark MacOS Installation: Step-by-Step Guide 🐍</title>
      <link href="/2024/04/07/pyspark-install-on-mac/"/>
      <url>/2024/04/07/pyspark-install-on-mac/</url>
      
        <content type="html"><![CDATA[<p>分為兩部分介紹如何安裝 pyspark，</p><ol><li>安裝：介紹使用 pyspark 前所需安裝的所有工具與軟體。</li><li>檢查：安裝完畢後，測試是否能順利開啟 spark 與 pyspark。<br>話不多說，開始來安裝吧～</li></ol><h2 id="安裝"><a href="#安裝" class="headerlink" title="安裝"></a>安裝</h2><p>在安裝階段，我們需要安裝 Java、Scala 與 Apache Spark，並且安裝 pyspark 套件。<br>而在安裝這些軟體前，我們需要 Xcode 與 Homebrew 這兩項工具。</p><ol><li><p>Xcode: Apple’s Command Line Tools<br>在終端機輸入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcode-select --install</span><br></pre></td></tr></table></figure><p>接者在彈跳視窗點按 install 即可。</p></li><li><p>安裝 Homebrew<br><a href="https://brew.sh/">Homebrew</a> 是一個開源的套件管理器，其使用非常簡單所以可以節省很多的精力。<br>我們後續也會使用 homebrew 安裝 Java、Scala 與 spark。<br>到 homebrew 的頁面造著指示安裝即可。<br>官網連結：<br><a href="https://brew.sh/">Homebrew Downloads｜Homebrew</a><br>如果不確定自己是否有安裝 homebrew 或是安裝完成想檢查是否成功的話，可以輸入 <code>brew</code> 或是 <code>which brew</code>，如果有成功出現 Example usage 或是 brew 的路徑代表成功～</p><img src="/2024/04/07/pyspark-install-on-mac/homebrew.png" class=""></li><li><p>安裝 java<br>可以先下 <code>java -version</code> 檢查電腦是否有 java 了<br>如果沒有的，直接至 oracle 官網下載 JDK 安裝包。<br>官網連結：<br><a href="https://www.oracle.com/java/technologies/downloads/">Java Downloads | Oracle</a><br>選取 macOS 後，依照電腦芯片安裝對應的 DMG Installer，intel 為 x64，apple silicon 為 ARM64。</p><img src="/2024/04/07/pyspark-install-on-mac/oracle_java.png" class=""><p>安裝完成後，打開終端機，一樣輸入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure><p>顯示以下訊息代表正確安裝～</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java version &quot;22&quot; 2024-03-19</span><br><span class="line">Java(TM) SE Runtime Environment (build 22+36-2370)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 22+36-2370, mixed mode, sharing)</span><br></pre></td></tr></table></figure></li><li><p>安裝 scala<br>一樣可以先利用 <code>scala -version</code> 檢查是否有 scala，<br>如果沒有：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install scala</span><br></pre></td></tr></table></figure></li><li><p>安裝 spark<br>直接輸入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install apache-spark</span><br></pre></td></tr></table></figure></li><li><p>安裝 pyspark<br>pyspark 是一個作為 python 與 spark 接口的套件，也就是直接利用 <code>pip</code> 即可，其中記得切換到你正在使用的虛擬環境。</p></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name your_venv_name python=3.8</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate your_venv_name</span><br><span class="line">pip install pyspark</span><br></pre></td></tr></table></figure><h2 id="檢查"><a href="#檢查" class="headerlink" title="檢查"></a>檢查</h2><p>做完上述步驟，即完成 pyspark 的安裝，我們可以來檢查一下是否安裝成功。</p><ol><li><p>spark<br>在終端機輸入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell</span><br></pre></td></tr></table></figure><p>成功的話會如下圖所示，並進入 scala 環境，接著輸入 <code>:q</code> 退出環境。</p><img src="/2024/04/07/pyspark-install-on-mac/spark_check.png" class=""></li><li><p>pyspark<br>接著測試我們真正使用的 pyspark，開啟 jupyter notebook，輸入以下的程式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext()</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark = SparkSession.builder.getOrCreate()</span><br></pre></td></tr></table></figure></li></ol><p>如此以來，就完成 pyspark 的安裝拉（撒花 🎉</p><p>此文章同步於 <a href="https://medium.com/@bensonhsieh/pyspark-macos-installation-step-by-step-guide-1e5ff00e8efd">Medium</a>。<br>也歡迎大家傳送 Linkedin 連結邀請給我。<a href="https://www.linkedin.com/in/%E5%8D%9A%E4%B8%9E-%E8%AC%9D-4396b7235/">Linkedin Profile</a></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Quickly Debug Python Code with ipdb！</title>
      <link href="/2024/03/17/debugging-in-python-with-ipdb/"/>
      <url>/2024/03/17/debugging-in-python-with-ipdb/</url>
      
        <content type="html"><![CDATA[<p>在程式世界裡，抓蟲（debug）是個不可避免的坑，能不能高效的除錯技巧更是每位工程師和資料科學家痛 🥲。最近因為工作的關係，接手程式需要進行優化，在嘗試理解的過程中碰到一個除錯強大工具 ipdb，跟大家分享！<br>ipdb 是一個第三方互動式除錯工具。ipdb 建立了一個互動式 shell 讓我們可以輕鬆地進行程式測試與除錯，非常方便。</p><span id="more"></span><h3 id="How-to-Debug"><a href="#How-to-Debug" class="headerlink" title="How to Debug"></a>How to Debug</h3><p>相信大家都有遇過：「程式有 error 但不知道為什麼出錯 … 程式跑起來了！… WHY！！！」的囧境 Orz</p><img src="/2024/03/17/debugging-in-python-with-ipdb/ipdb_meme.png" class=""><p>初學者在 debug 時可能會使用 <code>print</code> 、<code>logging</code> 打印出段落中的訊息以判斷程式是否如預期運作，或是加入 <code>Exception Handling</code> 、<code>assertions</code> 做異常處理，更有經驗的工程師可能能更善用如 PyCharm、VSCode 這些 IDE 所提供的除錯功能或是撰寫單元測試。而我們也可以透過 ipdb 這個工具來幫助我們了解目前環境變數的變化。那，ipdb 究竟是什麼？</p><h3 id="What’s-ipdb"><a href="#What’s-ipdb" class="headerlink" title="What’s ipdb"></a>What’s ipdb</h3><p><a href="https://pypi.org/project/ipdb/">ipdb</a> 全名 IPython-enables python debugger，其透過 IPython 擴展了 pdb 原有的基本功能，讓我們可以藉由 ipdb 建立的互動式 shell 執行 python 程式，不論是想看函數參數傳入內容是否正確、dataframe 或是 tensor 的 shape，甚至想寫額外測試的程式都可以輕鬆做到。</p><p>使用 ipdb 就跟使用 pdb 時一樣簡單，將套件載入後，於想設置斷點的地方添加以下程式片段：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!pip install ipdb</span><br><span class="line"><span class="keyword">import</span> ipdb</span><br><span class="line">ipdb.set_trace()</span><br></pre></td></tr></table></figure><p>也可以直接在命令列輸入以下指定啟動 ipdb 調校模式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m ipdb script.py</span><br></pre></td></tr></table></figure><h3 id="ipdb-cheatsheet"><a href="#ipdb-cheatsheet" class="headerlink" title="ipdb cheatsheet"></a>ipdb cheatsheet</h3><ul><li>h：print 出可用的命令或特定命令</li><li>q：退出程式</li><li>n：繼續執行，直到達到單前函數中的下一行，或著他返回</li><li>c：繼續執行直到下個斷點或結束</li><li>a：print 出當前函數的參數</li><li>p：print 出變數的值</li></ul><p>當進入 ipdb 的互動式環境後，可以調用以上指令進行操作，例如執行下一行或是退出整個程式。</p><h3 id="ipdb-實戰演練"><a href="#ipdb-實戰演練" class="headerlink" title="ipdb 實戰演練"></a>ipdb 實戰演練</h3><p>這裡示範使用<code>ipdb.set_trace()</code> 該如何進行除錯，通常會是在命令列作使用，而我們也可以在 jupyter notebook 做簡單測試，<br>我們使用 PyTorch 與 iris 資料集，建立一個很簡單的神經網路做預測模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ipdb</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset, DataLoader</span><br><span class="line">le = LabelEncoder()</span><br><span class="line"></span><br><span class="line">iris = sm.datasets.get_rdataset(<span class="string">&#x27;iris&#x27;</span>).data</span><br><span class="line">iris.iloc[:, -<span class="number">1</span>] = le.fit_transform(iris.iloc[:, -<span class="number">1</span>])</span><br><span class="line">iris = np.array(iris)</span><br><span class="line">dataset = TensorDataset(torch.tensor(iris[:, :-<span class="number">1</span>], dtype=torch.<span class="built_in">float</span>), torch.tensor(iris[:, -<span class="number">1</span>], dtype=torch.long))</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">2</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">myNN</span>(nn.Module):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">super</span>(myNN, self).__init__()</span><br><span class="line">    self.fc1 = nn.Linear(<span class="number">4</span>, <span class="number">10</span>)</span><br><span class="line">    self.fc2 = nn.Linear(<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">    self.fc3 = nn.Linear(<span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    x = torch.relu(self.fc1(x))</span><br><span class="line">    x = torch.relu(self.fc2(x))</span><br><span class="line">    x = self.fc3(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = myNN()</span><br><span class="line">loss_func = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">  <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">    inputs, labels = data</span><br><span class="line">    ipdb.set_trace()</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    loss = loss_func(outputs.squeeze(), labels)</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;epoch: <span class="subst">&#123;i&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><p>在訓練迴圈中，每個 batch 會作為 inputs 餵給模型輸出預測結果 ouputs，我們可以在 <code>outputs = model(inputs)</code> 前利用 <code>ipdb.set_trace()</code> 設置斷點，<br>目的是為了查看 inputs 資料長什麼樣子，因為在 CV、NLP 模型中，資料時常會先做許多 transform 函數才進入模型，此時就可能會想要確認模型輸入的資料細節。</p><video width="100%" controls>    <source src="ipdb.mov" type="video/mp4"></video><p>當程式碼跑到該行時，就會看到跳出 ipdb 的互動式 shell，可以在裡面下 cheatsheet 提到的參數，或是寫 Python 程式，<br>例如可以查看 inputs.shape 或是直接打印出資料內容。而輸入 c 會跳到下一個 epoch，n 會執行下一行，q 則會直接退處整個程式。</p><h3 id="ipdb-缺點"><a href="#ipdb-缺點" class="headerlink" title="ipdb 缺點"></a>ipdb 缺點</h3><ol><li>Limited  Debugging：ipdb 雖然具有互動式調校非常方便，但對於更複雜的問題（例如：multithreaded application），ipdb 的調校能力將會受到限制。</li><li>Slow：因為是逐步執行，可能會較耗時，因此可能不適合大型的應用產品、程式</li></ol><p>總結來說，ipdb 提供非常直觀、輕鬆的方式，用交互模式讓開發人員可以進行除錯，雖然在大型、複雜程式的情境可能沒那麼適合，但依舊是一個非常強大方便得工具。</p><h3 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h3><p><a href="https://www.freecodecamp.org/news/python-debugging-handbook/">freeCodeCamp Python Debugging Handbook - How to Debug Your Python Code</a><br><a href="https://youtu.be/RYkEoCkJWeA?si=uiUgBy6wu-xwq9w5">台大資訊 深度學習之應用|ADL TA Recitation: PyTorch Debugging 有BUG怎麼辦!?</a></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> debug </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Getting Started with Regexp, Simple and Clear 🤗</title>
      <link href="/2024/03/14/hello%20regexp/"/>
      <url>/2024/03/14/hello%20regexp/</url>
      
        <content type="html"><![CDATA[<p>正則表達式（RegExp）是一種用於字符串搜索和替換的強大模式匹配語言。<br>通過定義特定的模式，它可以快速識別和提取文本數據中的關鍵信息，從而使數據處理變得更加高效和精確。<br>無論是數據清洗、日誌分析還是自然語言處理，正則表達式都是不可或缺的工具，幫助我們從繁雜的數據中提煉出有價值的信息。</p><span id="more"></span><h2 id="什麼情況會使用到-RegExp｜以車禍案件篩選為例"><a href="#什麼情況會使用到-RegExp｜以車禍案件篩選為例" class="headerlink" title="什麼情況會使用到 RegExp｜以車禍案件篩選為例"></a>什麼情況會使用到 RegExp｜以車禍案件篩選為例</h2><p>以 <strong>找到車禍案件為例</strong>，下面整理出 7 則在判決中會出現的片段，我們的任務是要找到車禍案件，<br>首先，我們先觀察一下是否有一定的規律可以進行歸納。</p><ol><li>就本件<strong>車禍</strong>之發生自有過失，應就原告所受損害負賠償責任 </li><li>足見被告對系爭<strong>車禍</strong>之發生，顯有過失 </li><li>原告看到被告之機<strong>車</strong>停放於原告與陳明風同住之系爭住所外，原告早已耳聞兩人之間有曖昧關係</li><li>在前開191號房屋<strong>車</strong>庫門邊又拿了一條拉鐵門用的鐵條</li><li>隨即緊急煞車暫停於<strong>車</strong>道，致陳維德煞<strong>車</strong>不及，<strong>撞</strong>及上訴人<strong>車</strong>輛後端（下稱系爭事故）</li><li>被告由後方追<strong>撞</strong>原告之<strong>車</strong>輛，原告因而受有左側足部壓砸傷</li><li>甚至遭原告吐口水及左肩碰<strong>撞</strong>陸續之挑釁，…，該鐵條不但影響<strong>車</strong>輛進出 …</li></ol><p>❓ 我們發現 …</p><ol><li>不一定每篇車禍判決皆會提及車禍 → 只用車禍去篩選會漏掉許多資料，例如第5, 6筆資料</li><li>非車禍案件也有很多提到車的可能 → 只用車去篩選也不宜，例如第3, 4 筆資料</li><li>車禍案件更常會同時提及撞 … 車 …，且兩字會在附近</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">data = [...,</span><br><span class="line">        ...,]</span><br><span class="line"></span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> data:</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;車禍&#x27;</span> <span class="keyword">in</span> text: <span class="comment"># 如果車禍出現在文中，可認為為車禍案件</span></span><br><span class="line">        result.append(text)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;車&#x27;</span> <span class="keyword">in</span> text: <span class="comment"># 如果車出現，判斷附近是否出現撞</span></span><br><span class="line">        car_index = text.index(<span class="string">&#x27;車&#x27;</span>)</span><br><span class="line">        sub_text = text[<span class="built_in">max</span>(car_index - <span class="number">10</span>, <span class="number">0</span>): <span class="built_in">min</span>(car_index + <span class="number">10</span>, <span class="built_in">len</span>(text))]</span><br><span class="line">        <span class="built_in">print</span>(sub_text)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;撞&#x27;</span> <span class="keyword">in</span> sub_text: <span class="comment"># 如果出現撞，則符合設定之規則</span></span><br><span class="line">            result.append(text)</span><br></pre></td></tr></table></figure><p>上面的做法有以下兩個問題，也是為什麼我們希望使用正則要表達對字串的篩選邏輯</p><ol><li>可讀性低</li><li>維護性低</li></ol><ul><li>使用正則的話</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> data:</span><br><span class="line">    <span class="keyword">if</span> re.search(<span class="string">r&#x27;車禍|車.&#123;0,10&#125;撞|撞.&#123;0,10&#125;車&#x27;</span>):</span><br><span class="line">        result.append(text)</span><br></pre></td></tr></table></figure><hr><h2 id="什麼是正規表達式-Regular-Expression"><a href="#什麼是正規表達式-Regular-Expression" class="headerlink" title="什麼是正規表達式 Regular Expression"></a>什麼是正規表達式 Regular Expression</h2><blockquote><p>利用 <strong>文字</strong> 與一系列 <strong>定義好的符號</strong> 所組合而成的 <strong>規則模式（pattern）</strong>，用來匹配我們的 <strong>目標字串。<br>車禍|車.{0,5}撞|撞.{0,5}車</strong></p></blockquote><p>搭配支援正則表達的工具、套件，對字串做 <strong>搜尋</strong>、<strong>替換</strong> 等處理。</p><blockquote></blockquote><h2 id="該怎麼使用正則"><a href="#該怎麼使用正則" class="headerlink" title="該怎麼使用正則"></a>該怎麼使用正則</h2><img src="/2024/03/14/hello%20regexp/regexp_meme.png" class=""><h3 id="RegExp-常見特殊符號"><a href="#RegExp-常見特殊符號" class="headerlink" title="RegExp 常見特殊符號"></a><strong>RegExp 常見特殊符號</strong></h3><table><thead><tr><th>符號</th><th>解釋</th></tr></thead><tbody><tr><td><code>.</code></td><td>比對換行符<code>\n</code>以外所有字元</td></tr><tr><td><code>\w</code></td><td>英文字母與數字</td></tr><tr><td><code>\s</code></td><td>空白、換行符 <code>\n</code>、回車符 <code>\r</code>tab <code>\t</code></td></tr><tr><td><code>|</code></td><td>代表 or，用於連結兩種 pattern</td></tr></tbody></table><table><thead><tr><th>符號</th><th>解釋</th></tr></thead><tbody><tr><td><code>?</code></td><td>0 或一次</td></tr><tr><td><code>+</code></td><td>連續出現一次以上</td></tr><tr><td><code>&#123;x&#125;</code></td><td>x 次</td></tr><tr><td><code>&#123;x,y&#125;</code></td><td>x~y 次</td></tr></tbody></table><h3 id="小練習"><a href="#小練習" class="headerlink" title="小練習"></a><strong>小練習</strong></h3><p>下列哪個正規表達式 <strong>無法</strong> 比對到 <code>google</code>？</p><ol><li><code>g\s+gle</code></li><li><code>g\w&#123;1,&#125;gle</code></li><li><code>go+gle</code></li></ol><h3 id="Python-re-套件介紹"><a href="#Python-re-套件介紹" class="headerlink" title="Python re 套件介紹"></a><strong>Python re 套件介紹</strong></h3><blockquote><p><strong>設定 pattern → 判斷字串中是否有這個 pattern → 我的 pattern 對應到的字是什麼</strong></p></blockquote><p>在 python 中，我們可以透過 <code>re</code> 這個套件執行正則表達式的操作</p><ol><li><p>設定 pattern → <code>re.compile()</code></p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;小明從光復路由北往南方向直行，遭被告駕駛上開車輛左側碰撞而倒車，小明很生氣&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用 re.compile 設定正規表達式</span></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;車禍|撞.&#123;0,10&#125;車|車.&#123;0,10&#125;撞&#x27;</span>)</span><br></pre></td></tr></table></figure></li><li><p>字串是否符合我們要的 pattern → <code>re.search()</code></p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;re.search(pattern=pattern, </span><br><span class="line">                    string=text)</span><br><span class="line"><span class="comment"># 在 index=22~28 match 到 ‘車輛左側碰撞’ 符合我們的規則</span></span><br><span class="line">&lt;re.Match <span class="built_in">object</span>; span=(<span class="number">22</span>, <span class="number">28</span>), <span class="keyword">match</span>=<span class="string">&#x27;車輛左側碰撞&#x27;</span>&gt; </span><br></pre></td></tr></table></figure></li><li><p>提取匹配到的字串 → <code>re.search().group()</code></p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;re.search(pattern, text).group()</span><br><span class="line"><span class="string">&#x27;車輛左側碰撞&#x27;</span></span><br></pre></td></tr></table></figure></li><li><p>結合 pd.Series 找出符合規則的資料 → <code>pd.Series.str.contains()</code></p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;車禍|撞.&#123;0,10&#125;車|車.&#123;0,10&#125;撞&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt;data = pd.DataFrame(&#123;<span class="string">&#x27;text&#x27;</span>: </span><br><span class="line">        [<span class="string">&#x27;小明從光復路由北往南方向直行，遭被告駕駛上開車輛左側碰撞而倒車，小明很生氣&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;abcdefghijklmnopgrstuvwxyz&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;甲乙丙丁戊&#x27;</span>]&#125;)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;data.text.<span class="built_in">str</span>.contains(pat=pattern)</span><br><span class="line"><span class="number">0</span>     <span class="literal">True</span></span><br><span class="line"><span class="number">1</span>     <span class="literal">False</span></span><br><span class="line"><span class="number">2</span>     <span class="literal">False</span></span><br></pre></td></tr></table></figure></li><li><p>想用 SQL 撈？→<code>RLIKE</code>  （適用HAP)</p> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> context</span><br><span class="line"><span class="keyword">FROM</span> the_table</span><br><span class="line"><span class="keyword">WHERE</span> context RLIKE <span class="string">&#x27;車禍|撞.&#123;0,10&#125;車|車.&#123;0,10&#125;撞&#x27;</span></span><br></pre></td></tr></table></figure></li></ol><hr><h2 id="工具分享"><a href="#工具分享" class="headerlink" title="工具分享"></a>工具分享</h2><p><a href="https://regex101.com/">regex101: build, test, and debug regex</a></p><img src="/2024/03/14/hello%20regexp/regex101.png" class=""><hr><h2 id="學習資源"><a href="#學習資源" class="headerlink" title="學習資源"></a>學習資源</h2><p><a href="https://youtu.be/hy3sd9MOAcc?si=pq3WcCyCtBCAywth">CS50</a><br><a href="https://www.datacamp.com/tutorial/python-regular-expression-tutorial">DataCamp</a><br><a href="https://www.w3schools.com/python/python_regex.asp">W3School</a></p>]]></content>
      
      
      <categories>
          
          <category> nlp </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> nlp </tag>
            
            <tag> regexp </tag>
            
            <tag> sql </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
